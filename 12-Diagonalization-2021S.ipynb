{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_decom(A, tol=0.0001):\n",
    "    n = A.shape[0]\n",
    "    vals,vecs = LA.eigh(A)\n",
    "    \n",
    "    inds = np.where((vals[1:] - vals[:-1]) > tol)[0]\n",
    "    starts = np.hstack([np.array([0]), inds+1])\n",
    "    ends = np.hstack([inds+1, np.array([n])])\n",
    "    \n",
    "    dist_vals = vals[starts]\n",
    "    projs = np.zeros((len(dist_vals), n, n))\n",
    "    i = 0\n",
    "    for s,e in zip(starts,ends):\n",
    "        space = vecs[:,s:e]\n",
    "        projs[i] = space.dot(space.T)\n",
    "        i += 1\n",
    "    \n",
    "    return dist_vals, projs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every $n\\times n$ symmetric matrix $A$, there is an orthogonal basis $\\beta = {\\{\\bf u}_1, \\ldots, {\\bf u}_n\\}$ and $n$ numbers $\\lambda_1,\\ldots,\\lambda_n$ such that $A{\\bf u}_i=\\lambda_i{\\bf u}_i$ for all $i$.  \n",
    "Recall that $\\lambda_i$'s are the eigenvalues and   \n",
    "${\\bf u}_i$'s are the eigenvectors.  \n",
    "We call $\\beta$ an **eigenbasis** of $A$.\n",
    "\n",
    "Let $Q$ be the matrix whose columns are vectors in $\\beta$ and $D$ the diagonal matrix whose diagonal entries are $\\lambda_1,\\ldots,\\lambda_n$.  Then  \n",
    "$$AQ = \n",
    "A\\begin{bmatrix}\n",
    " | & ~ & | \\\\\n",
    " {\\bf u}_1 & \\cdots & {\\bf u}_n \\\\\n",
    " | & ~ & | \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    " | & ~ & | \\\\\n",
    " \\lambda_1{\\bf u}_1 & \\cdots & \\lambda_n{\\bf u}_n \\\\\n",
    " | & ~ & | \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    " | & ~ & | \\\\\n",
    " {\\bf u}_1 & \\cdots & {\\bf u}_n \\\\\n",
    " | & ~ & | \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    " \\lambda_1 & ~ & ~ \\\\\n",
    " ~ & \\ddots & ~ \\\\\n",
    " ~ & ~ & \\lambda_n \n",
    "\\end{bmatrix} = \n",
    "QD.$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, for every symmetric matrix $A$, there is an orthogonal matrix $Q$ and a diagonal matrix $D$ such that  \n",
    "$$A = QDQ^\\top \\text{ and } D = Q^\\top AQ$$  \n",
    "with $Q^\\top Q = QQ^\\top = I$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, $A$ can also be written as  \n",
    "$$A = QDQ^\\top = \\sum_{i = 1}^n \\lambda_i {\\bf u}_i{\\bf u}_i^\\top.$$  \n",
    "Note that each ${\\bf u}_i{\\bf u}_i^\\top$ is a projection matrix onto the straight line spanned by ${\\bf u}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `LA.eigh`\n",
    "- eigenbasis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "A = np.eye(3) - np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Verify that $A = QDQ^\\top$ and $Q^\\top Q = QQ^\\top = I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(3) - np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "np.set_printoptions(precision=2,suppress=True)\n",
    "print(A)\n",
    "print(Q.dot(D).dot(Q.T))\n",
    "print(Q.T.dot(Q))\n",
    "print(Q.dot(Q.T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Let ${\\bf u}$ be the $i$-th column of $Q$ and $\\lambda$ the $i$-th element of `vals`.  \n",
    "Verify that $A{\\bf u} = \\lambda{\\bf u}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Q.shape[1]): \n",
    "    u=Q[:,i]\n",
    "    ùúÜ=vals[i]\n",
    "    print(np.isclose(A.dot(u),ùúÜ*u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Verify that \n",
    "$$A = \\sum_i \\lambda_i {\\bf u}_i{\\bf u}_i^\\top,$$  \n",
    "where $\\lambda_i$ is the $i$-th element of `vals` and ${\\bf u}_i$ is the $i$-th column of $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA.eigh(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=np.zeros_like(A)\n",
    "for i in range(Q.shape[1]):\n",
    "    ùúÜ=vals[i]\n",
    "    u=Q[:,i]\n",
    "    u = u[:,np.newaxis]\n",
    "    B=B+ùúÜ*(u.dot(u.T))\n",
    "print(np.isclose(A,B))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(d)\n",
    "Let  \n",
    "```python\n",
    "v = np.array([1,1,1])\n",
    "```\n",
    "What are the projections of ${\\bf v}$ onto ${\\bf u}_0$, ${\\bf u}_1$, and ${\\bf u}_2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1,1,1])\n",
    "u0=Q[:,0]\n",
    "u0=u0[:,np.newaxis]\n",
    "u0Tu0inv=np.linalg.inv(u0.T.dot(u0))\n",
    "u00=u0.dot(u0Tu0inv).dot(u0.T).dot(v)\n",
    "u1=Q[:,1]\n",
    "u1=u1[:,np.newaxis]\n",
    "u1Tu1inv=np.linalg.inv(u1.T.dot(u1))\n",
    "u11=u1.dot(u1Tu1inv).dot(u1.T).dot(v)\n",
    "u2=Q[:,2]\n",
    "u2=u2[:,np.newaxis]\n",
    "u2Tu2inv=np.linalg.inv(u2.T.dot(u2))\n",
    "u22=u2.dot(u2Tu2inv).dot(u2.T).dot(v)\n",
    "print(u00)\n",
    "print(u11)\n",
    "print(u22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(e)\n",
    "Find a matrix $B$ such that  \n",
    "$B{\\bf u}_0 = 2{\\bf u}_0$  \n",
    "$B{\\bf u}_1 = 2{\\bf u}_1$  \n",
    "$B{\\bf u}_2 = 3{\\bf u}_2$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=[[2,0,0],[0,2,0],[0,0,3]]\n",
    "B=Q.dot(D).dot(Q.T)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "A = np.eye(3) - 2*np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "```\n",
    "Use `D` and `Q` to find the spectral decomposition of $A$.  \n",
    "Compare your answer with `spec_decom(A)` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(3) - 2*np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "DD=np.array=([-1,1])\n",
    "u0=Q[:,0]\n",
    "u0=u0[:,np.newaxis]\n",
    "u1=Q[:,1]\n",
    "u1=u1[:,np.newaxis]\n",
    "u2=Q[:,2]\n",
    "u2=u2[:,np.newaxis]\n",
    "u0u0T=u0.dot(u0.T)\n",
    "u1u1T=u1.dot(u1.T)\n",
    "u2u2T=u2.dot(u2.T)\n",
    "u1plusu2=u1u1T+u2u2T #u1 and u2 has same eigenvalue\n",
    "print(DD,u0u0,u1plusu2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_decom(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 3\n",
    "Let $E$ be a matrix.  \n",
    "The **Frobenius norm** of $E$ is defined as $\\|E\\| = \\sqrt{\\operatorname{tr}(E^\\top E)}$.  \n",
    "\n",
    "Let  \n",
    "```python\n",
    "A = np.eye(3) - 2*np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(a)\n",
    "Pick a column vector ${\\bf u}$ of $Q$ and let $P = {\\bf u}{\\bf u}^\\top$.  \n",
    "Find $\\|P\\|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(3) - 2*np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "u0=Q[:,0]\n",
    "u0=u0[:,np.newaxis]\n",
    "P=u0.dot(u0.T)\n",
    "print(np.linalg.norm(P))\n",
    "P1=u1.dot(u1.T)\n",
    "print(np.linalg.norm(P1))\n",
    "P2=u2.dot(u2.T)\n",
    "print(np.linalg.norm(P2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(b)\n",
    "Let  \n",
    "```python\n",
    "dist_vals, projs = spec_decom(A)\n",
    "```\n",
    "Pick a matrix $P$ in `projs` and find $\\|P\\|^2$.  \n",
    "If you look back at `vals`, can you guess the norm of each projection matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_vals, projs = spec_decom(A)\n",
    "P=projs[0]\n",
    "absP=np.linalg.norm(P)\n",
    "print(absP**2)\n",
    "vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 4\n",
    "Let  \n",
    "```python\n",
    "arr = plt.imread('circle.png')\n",
    "vals,vecs = LA.eigh(arr)\n",
    "```\n",
    "and $n = 216$.  \n",
    "Thus, `arr` is an $n\\times n$ matrix $A$.  \n",
    "Let $\\lambda_0\\leq\\ldots\\leq\\lambda_{n-1}$ be the eigenvalues of $A$ and ${\\bf u}_0,\\ldots {\\bf u}_{n-1}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(a)\n",
    "Pick a number $k$ between $0$ and $n-1$.  \n",
    "We have the inequality  \n",
    "$$\\|A - \\sum_{i = k}^{n-1} \\lambda_i{\\bf u}_i{\\bf u}_i^\\top\\| = \\|\\sum_{i=0}^{k-1}\\lambda_i{\\bf u}_i{\\bf u}_i^\\top\\|\\leq \\sum_{i=0}^{k-1}\\|\\lambda_i{\\bf u}_i{\\bf u}_i^\\top\\|\\leq \\sum_{i=0}^{k-1}\\lambda_i.$$  \n",
    "\n",
    "In other words, we can approximate $A$ by $\\sum_{i = k}^{n-1} \\lambda_i{\\bf u}_i{\\bf u}_i^\\top$ for some $k$.  \n",
    "Calculate $\\sum_{i = k}^{n-1} \\lambda_i{\\bf u}_i{\\bf u}_i^\\top$ with $k=210$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = plt.imread(\"circle.png\")\n",
    "plt.imshow(arr)\n",
    "vals,vecs = LA.eigh(arr)\n",
    "n=216\n",
    "sum=0\n",
    "for i in range(209,216):\n",
    "    u=vecs[:,i]\n",
    "    u=u[:,np.newaxis]\n",
    "    ut=u.T\n",
    "    ùúÜ=vals[i]\n",
    "    sum=sum+ùúÜ*u.dot(ut)\n",
    "print(sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(b)\n",
    "Let `approx` be your previous answer.  \n",
    "Use `plt.imshow(approx)` to see if the approximation looks good or not.  \n",
    "Note that `arr` occupies $n\\times n$ units memory.  \n",
    "In contrast, $\\lambda_k,\\ldots,\\lambda_{n-1}$ occupies $n-k$ units of memory and ${\\bf u}_k, \\ldots, {\\bf u}_{n-1}$ occupies $n\\times (n-k)$ units of memory.  \n",
    "In total, `approx` can be stored with $(n+1)\\times(n-k)$ units of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx=sum\n",
    "plt.imshow(approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[1,2,3],\n",
    "              [0,2,3],\n",
    "              [0,0,3]])\n",
    "vals,vecs = LA.eig(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5(a)\n",
    "Verify that $A = QDQ^{-1}$.  \n",
    "You may use `LA.inv` to calculate the inverse.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[0,2,3],[0,0,3]])\n",
    "vals,vecs = LA.eig(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "invQ=LA.inv(Q)\n",
    "\n",
    "QDinvQ=Q.dot(D).dot(invQ)\n",
    "\n",
    "\n",
    "print(QDinvQ)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5(b)\n",
    "Let ${\\bf u}$ be the $i$-th column of $Q$ and $\\lambda$ the $i$-th element of `vals`.  \n",
    "Verify that $A{\\bf u} = \\lambda{\\bf u}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2,suppress=True)\n",
    "for i in range(Q.shape[1]):\n",
    "    u=Q[:,i]\n",
    "    ùúÜ=vals[i]\n",
    "    print(np.isclose(A.dot(u),ùúÜ*u))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
