{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OX-7c-g_csaV"
   },
   "source": [
    "# KNeighborsClassifier from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4y2nvUYDcsaY"
   },
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHdyPqe0csaZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5HOnmVscsaa"
   },
   "source": [
    "## Algorithm\n",
    "**Input:**  \n",
    "- `X`: an array of shape `(N,d)` whose rows are samples and columns are features\n",
    "- `y`: the labels of shape `(N,)`\n",
    "- `k`: Numbers of neighbors (including self) to vote\n",
    "- `algorithm`: `'brute'`, `'ball_tree'`, or `'kd_tree'`\n",
    "\n",
    "**Output:**  \n",
    "A tuple `(predict, k_nearest_neighbors)`.  \n",
    "- `predict`: a function that takes data `X_sample` and output their predicted labels\n",
    "- `k_nearest_neighbors`: a function that takes data `X_sample` and return an array of shape `(X_sample_height, k)` that stores the indices of the nearest neighbors in `X` for each row in `X_sample`\n",
    "\n",
    "**Steps:**\n",
    "1. If `algorithm==\"brute\"`, create the function `k_nearest_neighbors` by the distance matrix.  \n",
    "2. If `algorithm==\"ball_tree\"` or `algorithm==\"kd_tree\"`, create the function `k_nearest_neighbors` by `sklearn.neighbors.NearestNeighbors` with the corresponding algorithm.\n",
    "3. Create the function `predict` that executes the following steps:\n",
    "    1. Input `X_sample` .\n",
    "    2. Let `nbrhoods = k_nearest_neighbors(X_sample)` .  \n",
    "    3. Let `votes = y[nbrhoods]` .\n",
    "    4. Calculate the most frequent label in each row of `votes` and store the results in `y_new` .\n",
    "    5. Return `y_new` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzaVZ2EMcsab"
   },
   "source": [
    "## Pseudocode\n",
    "Translate the algorithm into the pseudocode.  \n",
    "This helps you to identify the parts that you don't know how to do it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkyFMV3Xcsac"
   },
   "source": [
    "    1. \n",
    "    2. \n",
    "    3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1pc-9qAcsac"
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VX37epR8csad"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats #內含一些統計相關計算\n",
    "\n",
    "def dist_mtx(X, Y):     #定義距離如何計算\n",
    "    X_col = X[:,np.newaxis,:]\n",
    "    Y_row = Y[np.newaxis,:,:]\n",
    "    diff = X_col - Y_row\n",
    "    dist = np.linalg.norm(diff, axis=-1)\n",
    "    return dist\n",
    "\n",
    "def get_y(kneighbors, y):   #計算附近出現\"最多次的成員\"，即出現次數\n",
    "    # y[kneighbors] => pick the class value by the index of kneighbors\n",
    "    # use scipy.stats.mode to find out mode in y, and reshape to vectors\n",
    "    return stats.mode(y[kneighbors], axis=1).mode.reshape(kneighbors.shape[0])\n",
    "    #stats.mode:找出現最多次的成員\n",
    "    #先根據y[kneighbors]得到各個點是分到哪一類，再來去算最多的點是誰？最多人的那一個結果就是最終預測的答案，也就是我們常用的y_new\n",
    "\n",
    "def knn(X, y, algorithm, k):  #判斷輸入的點是哪一類,方法為用algorithm並依據訓練集判斷附近k個點哪一種類較多\n",
    "    # find out the indeices of k-neighbors\n",
    "    if algorithm == 'brute':\n",
    "        def k_nearest_neighbors(X_sample): \n",
    "            dist = dist_mtx(X_sample, X) #先算出目標點(X_Sample)與各個X的距離 \n",
    "            argp = dist.argpartition(k-1, axis=1)  #再找出前k-1個距離最小的index\n",
    "            return argp[:,:k] \n",
    "        def predict(X_sample):\n",
    "            k_neighbors = k_nearest_neighbors(X_sample)\n",
    "            return get_y(k_neighbors, y)\n",
    "            \n",
    "    elif algorithm in ['ball_tree', 'kd_tree']:\n",
    "        def k_nearest_neighbors(X_sample):\n",
    "            nbr = NearestNeighbors(n_neighbors=k, algorithm=algorithm)\n",
    "            nbr.fit(X)\n",
    "            return nbr.kneighbors(X_sample, return_distance=False)\n",
    "        def predict(X_sample):\n",
    "            k_neighbors = k_nearest_neighbors(X_sample)\n",
    "            return get_y(k_neighbors, y)\n",
    "    return predict, k_nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pv6Igkgecsaf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDj9JFzKcsaf"
   },
   "source": [
    "## Test\n",
    "Take some sample data from [KNeighborsClassifier-with-scikit-learn](KNeighborsClassifier-with-scikit-learn.ipynb) and check if your code generates similar outputs with the existing packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2s9SzwHcsaf"
   },
   "source": [
    "##### Name of the data\n",
    "Description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "l5QeA2rvcsag",
    "outputId": "c0fe499c-2c08-4370-afee-e66f247fe5ff"
   },
   "outputs": [],
   "source": [
    "mu1 = np.array([2.5,0])\n",
    "cov1 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "mu2 = np.array([-2.5,0])\n",
    "cov2 = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "y = np.array([0]*100 + [1]*100)\n",
    "\n",
    "X_test = np.random.rand(1000,2)*10-5 ##製造1000個點介於5~-5\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "y_new = model.predict(X_test)\n",
    "\n",
    "\n",
    "plt.scatter(*X.T,c=y)\n",
    "plt.scatter(*X_test.T,c=y_new,s=10,alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "iY3kqYuYcsah",
    "outputId": "670e8698-bb8b-4293-bc75-bbbe9db5ee28"
   },
   "outputs": [],
   "source": [
    "#用bruust演算法\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'brute', 5)\n",
    "y_new = predict(X_test)\n",
    "plt.figure(figsize=(6, 6)) \n",
    "plt.subplot(311).set_title('brute')\n",
    "plt.scatter(*X_test.T, c=y_new)\n",
    "#用ball_tree演算法\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'ball_tree', 5)\n",
    "y_new = predict(X_test)\n",
    "plt.subplot(312).set_title('ball_tree')\n",
    "plt.scatter(*X_test.T, c=y_new)\n",
    "#用kd_tree演算法\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'kd_tree', 5)\n",
    "y_new = predict(X_test)\n",
    "plt.subplot(313).set_title('kd_tree')\n",
    "plt.scatter(*X_test.T, c=y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5MgCSVHcsai"
   },
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utiUURY-csai"
   },
   "source": [
    "##### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*20 + [1]*20)\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaaaEeK9csai"
   },
   "source": [
    "###### 1(a)\n",
    "Train a $k$-nearest neighbors classification model by `X` and `y` .  \n",
    "Make a prediction of `X_sample` by:  \n",
    "1. your code with different algorithm settings\n",
    "2. `sklearn.neighbors.KNeighborsClassifier`\n",
    "\n",
    "The results should be the same.  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "WOKAX09-csai",
    "outputId": "e41363be-9f39-4f83-e7cb-627132dc5708"
   },
   "outputs": [],
   "source": [
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*20 + [1]*20)\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "\n",
    "#如上面分別用三種方式來做分類,並驗證答案與scikit相同\n",
    "\n",
    "#用bruust演算法\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'brute', 5)\n",
    "y_new_scratch_brute = predict(X_sample)\n",
    "plt.figure(figsize=(6, 6)) \n",
    "plt.subplot(311).set_title('brute')\n",
    "plt.scatter(*X_sample.T, c=y_new_scratch_brute)\n",
    "#用ball_tree演算法\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'ball_tree', 5)\n",
    "y_new_scratch_ball_tree = predict(X_sample)\n",
    "plt.subplot(312).set_title('ball_tree')\n",
    "plt.scatter(*X_sample.T, c=y_new_scratch_ball_tree)\n",
    "#用kd_tree演算法\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'kd_tree', 5)\n",
    "y_new_scratch_kd_tree = predict(X_sample)\n",
    "plt.subplot(313).set_title('kd_tree')\n",
    "plt.scatter(*X_sample.T, c=y_new_scratch_kd_tree)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X, y)\n",
    "y_new_scikit = model.predict(X_sample)\n",
    "\n",
    "print(((y_new_scratch_brute==y_new_scratch_ball_tree) &   #驗證我們自己寫出來的三種不同方式與scikit learn套件做出來的結果相同\n",
    "       (y_new_scratch_ball_tree==y_new_scratch_kd_tree) & \n",
    "       (y_new_scratch_kd_tree==y_new_scikit)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUX2taUNcsaj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NgKzxcecsaj"
   },
   "source": [
    "###### 1(b)\n",
    "Let `y_new` be the prediction of `X_sample` in the previous question. \n",
    "Plot the points (rows) in `X` with `c=y` .  \n",
    "Plot the points (rows) in `X_sample` with `c=y_new` and `alpha=0.1` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "fJ_BgHwocsaj",
    "outputId": "7e49935f-9386-46ba-e789-76e536ed406f"
   },
   "outputs": [],
   "source": [
    "#以brute為例畫圖\n",
    "plt.scatter(*X.T, c=y, label=\"Training data\", marker=\"^\", s=60) \n",
    "plt.scatter(*X_sample.T, c=y_new_scratch_brute, alpha=0.1, label=\"prediction\") #y_new = y_new_scratch_brute\n",
    "plt.legend(loc=\"upper left\") #標記在左上方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hT51bAw_csaj"
   },
   "source": [
    "###### 1(c)\n",
    "Let  \n",
    "```python\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "```  \n",
    "and let `k_nearest_neighbors` be one of the output of your function.  \n",
    "The results of `k_nearest_neighbors(X_sample)` should be the same as `model.kneighbors(X_sample, return_distance=False)` .  \n",
    "(The corresponding rows contains the same collection of elements, but might be in different order.)  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LD9HW2tcsak",
    "outputId": "2c0cb874-c262-4a13-c056-c7bb0c91164b"
   },
   "outputs": [],
   "source": [
    "#如上面的方式用brust做分類並比較與以KNeighborsClassifier做出來是否相等\n",
    "\n",
    "#brust\n",
    "predict, k_nearest_neighbors = knn(X, y, 'brute',3)\n",
    "neighbors = k_nearest_neighbors(X_sample)\n",
    "#KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X, y)\n",
    "print((neighbors==model.kneighbors(X_sample, return_distance=False)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuBoLNJEcsak"
   },
   "source": [
    "##### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2)\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n))\n",
    "xx = np.zeros((frames, m, n))\n",
    "count =  0\n",
    "for i in range(m-2):\n",
    "    for j in range(n-2):\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0idMozQcsak"
   },
   "source": [
    "###### 2(a)\n",
    "Run  \n",
    "```python\n",
    "plt.imshow(oo[i], cmap=\"Greys\")\n",
    "```\n",
    "with different `i` .  \n",
    "Guess what is the meaning of `oo` and `xx` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Z029XMycsak"
   },
   "outputs": [],
   "source": [
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2) #6x6\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n)) #(36,8,8)\n",
    "xx = np.zeros((frames, m, n)) #(36,8,8)\n",
    "count =  0\n",
    "for i in range(m-2): #range(6)\n",
    "    for j in range(n-2): #range(6)\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "J2I2Q8XQcsal",
    "outputId": "2065ae28-f1be-4688-92dd-ed364efed359"
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        ax = plt.subplot2grid((6,6), (i,j)) #6x6個圖，這個圖是在(i,j)的位置\n",
    "        ax.imshow(oo[i*6+j], cmap=\"Greys\")\n",
    "print('oo是一個由36個子圖所組成，然後這組圖是：oo這個圖案，從左到右、從上到下的一個過程！')\n",
    "print('oo is a 36 images set, an o-like object in each image from left to right, up to down with step 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "huyI-3XQ_9z9",
    "outputId": "8b004783-7818-4e50-fe92-fbe5f3afbda8"
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        ax = plt.subplot2grid((6,6), (i,j)) #6x6個圖，這個圖是在(i,j)的位置\n",
    "        ax.imshow(xx[i*6+j], cmap=\"Greys\")\n",
    "print('xx是一個由36個子圖所組成，然後這組圖是：xx這個圖案，從左到右、從上到下的一個過程！')\n",
    "print('xx is a 36 images set, an x-like object in each image from left to right, up to down with step 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXYCYr-Ucsal"
   },
   "source": [
    "###### 2(b)\n",
    "Train a $k$-nearest neighbors classification model by `X` an `y` .  \n",
    "Make a prediction `y_new` for the training data `X` .  \n",
    "What is the outcome?  \n",
    "Can you give a reason to this phenomenon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STnMGNERcsal",
    "outputId": "44a32463-fdd5-4948-88e6-4503d1957069"
   },
   "outputs": [],
   "source": [
    "#X = np.vstack([oo, xx]).reshape(2*frames, -1) #(72, 64)\n",
    "#y = np.array([0]*frames + [1]*frames) #(72,)\n",
    "\n",
    "for k in range(1,10):\n",
    "    predict, k_nearest_neighbors = knn(X, y, 'brute', k)\n",
    "    y_new = predict(X) #(72,)\n",
    "    print(\"k = \",k,\"\\n\",y_new,\"\\n\") \n",
    "#k = 1:預測一定正確，因為用自己來預測，y = y_new\n",
    "#不同的k會有不同的預測結果，因為圈到不同的點，所以決策結果會不同！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoNeOxukHsU7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TA:\n",
    "Well done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML7 KNeighborsClassifier-from-scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
