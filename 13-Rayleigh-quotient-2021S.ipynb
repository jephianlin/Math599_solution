{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rayleigh quotient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a symmetric matrix $A$ has eigenvalues  \n",
    "$$\\lambda_0\\leq \\cdots \\leq\\lambda_{n-1}.$$\n",
    "Then  \n",
    "$$\\max_{{\\bf x}\\neq {\\bf 0}}\\frac{{\\bf x}^\\top A{\\bf x}}{{\\bf x}^\\top {\\bf x}} = \\max_{\\|{\\bf x}\\| = 1} {\\bf x}^\\top A{\\bf x} = \\lambda_{n-1}$$\n",
    "and \n",
    "$$\\min_{{\\bf x}\\neq {\\bf 0}}\\frac{{\\bf x}^\\top A{\\bf x}}{{\\bf x}^\\top {\\bf x}} = \\min_{\\|{\\bf x}\\| = 1} {\\bf x}^\\top A{\\bf x} = \\lambda_{0}.$$\n",
    "The vector ${\\bf x}$ that achieve the maximum or the minimum is an eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if ${\\bf u}_0,\\ldots,{\\bf u}_{n-1}$ form an eigenbasis with respect to the eigenvalues $\\lambda_0,\\ldots,\\lambda_{n-1}$, then  \n",
    "$$\\max_{\\substack{{\\bf x}\\neq {\\bf 0}\\\\{\\bf x}\\perp L_k}}\\frac{{\\bf x}^\\top A{\\bf x}}{{\\bf x}^\\top {\\bf x}} = \\max_{\\substack{\\|{\\bf x}\\| = 1\\\\{\\bf x}\\perp L_k}} {\\bf x}^\\top A{\\bf x} = \\lambda_{k+1}$$\n",
    "and \n",
    "$$\\min_{\\substack{{\\bf x}\\neq {\\bf 0}\\\\{\\bf x}\\perp U_k}}\\frac{{\\bf x}^\\top A{\\bf x}}{{\\bf x}^\\top {\\bf x}} = \\min_{\\substack{\\|{\\bf x}\\| = 1\\\\{\\bf x}\\perp U_k}} {\\bf x}^\\top A{\\bf x} = \\lambda_{k-1},$$\n",
    "where $L_k = \\operatorname{span}(\\{{\\bf u}_0,\\ldots,{\\bf u}_k\\})$ and $U_k = \\operatorname{span}(\\{{\\bf u}_k,\\ldots,{\\bf u}_{n-1}\\})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Covariance matrix\n",
    "- Laplacian matrix and its Rayleigh quotient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "A = np.ones((3,3))\n",
    "vs = np.random.randn(3,100)\n",
    "vs = vs / np.linalg.norm(vs, axis=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Generate an array of ${\\bf x}^\\top A{\\bf x}$, where ${\\bf x}$ runs through the columns of `vs` .  \n",
    "Find the minimum and the maximum.  \n",
    "Compare them to the smallest and the largest eigenvalues of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.ones((3,3))\n",
    "vs = np.random.randn(3,1000)\n",
    "vs = vs / np.linalg.norm(vs, axis=0)\n",
    "\n",
    "a=np.sum(vs*(A.dot(vs)),axis=0)\n",
    "print(min(a),max(a))\n",
    "print(np.linalg.eigh(A)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "It is known that \n",
    "```python\n",
    "u2 = np.array([1,1,1])\n",
    "```\n",
    "is the eigenvector for the largest eigenvalue $\\lambda_2 = 3$.  \n",
    "Generate 10000 random points of length 1 in $\\mathbb{R}^3$.  \n",
    "Select those that are (almost) perpendicular to `u2` .  \n",
    "Calculate the maximum of ${\\bf x}^\\top {\\bf x}$ over these points ${\\bf x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "u2 = np.array([1,1,1])\n",
    "vs = np.random.randn(3,10000)\n",
    "vs1 = vs / np.linalg.norm(vs, axis=0)\n",
    "Avs = u2.dot(vs1) ### 1 x 3 times 3 x 10000\n",
    "mask = (np.abs(Avs) < 0.01) #T or F\n",
    "\n",
    "new_vs = vs1[:, mask]\n",
    "%matplotlib notebook\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlim(-5,5)\n",
    "ax.set_ylim(-5,5)\n",
    "ax.set_zlim(-5,5)\n",
    "ax.scatter(new_vs[0], new_vs[1], new_vs[2])\n",
    "a=np.sum(new_vs*(A.dot(new_vs)),axis=0)\n",
    "max(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "mu = np.array([0,0])\n",
    "cov = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "vs = np.random.multivariate_normal(mu, cov, 100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Plot the points (rows) in `vs` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "mu = np.array([0,0])\n",
    "cov = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "vs = np.random.multivariate_normal(mu, cov, 100)\n",
    "\n",
    "plt.scatter(vs[:,0],vs[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "You may consider switching back to `%matplotlib inline` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "Find the center of mass over the points in `vs` .  \n",
    "Shift the points in `vs` so that the center is at the origin.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "center=np.mean(vs[:,0]),np.mean(vs[:,1])\n",
    "plt.scatter(vs[:,0]-center[0],vs[:,1]-center[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(c)\n",
    "Suppose $X$ is a $N\\times d$ data matrix whose rows are samples and columns are features.  \n",
    "If the rows are centered at the origin, then $\\frac{1}{N}X^\\top X$ is called the **covariance matrix** between the features.\n",
    "\n",
    "Thinking of `vs` as a data matrix whose rows are centered at the origin, find the covariance matrix `C` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "mu = np.array([0,0]) ##(2,)\n",
    "cov = np.array([[1.1, 1],\n",
    "         [1 , 1.1]]) ##(2, 2)\n",
    "vs = np.random.multivariate_normal(mu, cov, 100) ##(100, 2)\n",
    "\n",
    "print((1/100)*(vs.T.dot(vs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(d)\n",
    "Generate 100 vectors of length 1 in $\\mathbb{R}^2$.  \n",
    "Find the smallest Rayleigh quotient and the vector ${\\bf u}_0$ that achieve it.  \n",
    "Find the largest Rayleigh quotient and the vector ${\\bf u}_1$ that achieve it.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "mu = np.array([0,0])\n",
    "cov = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "vs = np.random.multivariate_normal(mu, cov, 100)#100*2\n",
    "A = np.ones((2,2))#2*2\n",
    "vs = vs / np.linalg.norm(vs, axis=0)\n",
    "print(np.linalg.eigh(A)[0])\n",
    "u0=np.linalg.eigh(A)[1][0]\n",
    "u1=np.linalg.eigh(A)[1][1]\n",
    "print(np.sum(u0.T*(A.dot(u0.T)),axis=0),np.sum(u1.T*(A.dot(u1.T)),axis=0))\n",
    "print(np.isclose(np.linalg.eigh(A)[0][0],np.sum(u0.T*(A.dot(u0.T)),axis=0)))\n",
    "print(np.isclose(np.linalg.eigh(A)[0][1],np.sum(u1.T*(A.dot(u1.T)),axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "The code calculate `np.linalge.eigh(A)` many times.  \n",
    "This can be bad if this command takes a long time.  \n",
    "It would be nice to store its results for future uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(e)\n",
    "Plot the points in the shifted `vs` .  \n",
    "Draw the vectors ${\\bf u}_0$ and ${\\bf u}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "mu = np.array([0,0]) ##(2,)\n",
    "cov = np.array([[1.1, 1],\n",
    "         [1 , 1.1]]) ##(2, 2)\n",
    "vs = np.random.multivariate_normal(mu, cov, 100) ##(100, 2)\n",
    "\n",
    "center = np.mean(vs[:,0]),np.mean(vs[:,1])\n",
    "plt.scatter(vs[:,0]-center[0],vs[:,1]-center[1])\n",
    "\n",
    "plt.arrow(0,0,*u0,head_width=0.2,color=\"red\")\n",
    "plt.arrow(0,0,*u1,head_width=0.2,color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "If you do `plt.axis('equal')`  \n",
    "you will realize the two vectors are orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 3\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[0,1,0,0,0],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [0,0,0,1,0]])\n",
    "vals,vecs = LA.eigh(A)\n",
    "```\n",
    "Let $\\lambda_0,\\ldots,\\lambda_4$ be the values in `vals` .  \n",
    "Let $\\beta = \\{{\\bf u}_0,\\ldots, {\\bf u}_4\\}$ be the column vectors in `vecs` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(a)\n",
    "Pick a random vector ${\\bf x}$ of length 1 in $\\mathbb{R}^5$.  \n",
    "Compute ${\\bf c} = [{\\bf x}]_\\beta = (c_0,\\ldots, c_4)^\\top$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.array([[0,1,0,0,0],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [0,0,0,1,0]])\n",
    "vals,vecs = LA.eigh(A)\n",
    "x = np.random.randn(5,1)\n",
    "x = x / np.linalg.norm(x, axis=0)\n",
    "c=vecs.T.dot(x)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Depending on the purpose,  \n",
    "sometimes the vector `x` is of the shape `(5,)`  \n",
    "and sometimes it is of the shape `(5,1)` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(b)\n",
    "Check that $\\|{\\bf x}\\|^2 = c_0^2 + \\cdots + c_4^2$.  \n",
    "Therefore, the condition $\\|{\\bf x}\\| = 1$ is equivalent to $c_0^2 + \\cdots + c_4^2 = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "np.power(c,2).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Alternatively, `np.sum(c**2, axis=0)` .  \n",
    "If `c.shape` is `(5,)`, then `np.sum(c**2)` is good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(c)\n",
    "Check that  \n",
    "$A{\\bf x} = c_0\\lambda_0{\\bf u}_0 + \\cdots + c_4\\lambda_4{\\bf u}_4$ and  \n",
    "${\\bf x}^\\top A{\\bf x} = c_0^2\\lambda_0 + \\cdots c_4^2\\lambda_4$.  \n",
    "Therefore, under the condition that $c_0^2 + \\cdots + c_4^2 = 1$, the extrema of ${\\bf x}^\\top A{\\bf x}$ are $\\lambda_0$ and $\\lambda_4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=c.T*vals.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ð´ð±=ð‘0ðœ†0ð®0+â‹¯+ð‘4ðœ†4ð®4\n",
    "np.isclose(A.dot(x),np.sum(np.matrix(cv*np.split(vecs, 5, axis=0)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ð±âŠ¤ð´ð±=ð‘20ðœ†0+â‹¯ð‘24ðœ†4\n",
    "np.isclose(np.sum(x*(A.dot(x)),axis=0),np.sum(np.power(c,2).T*vals.T,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[0,1,0,0,0],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [0,0,0,1,0]])\n",
    "vs = np.random.randn(5,100000)\n",
    "vs = vs / np.linalg.norm(vs, axis=0)\n",
    "\n",
    "a=np.sum(vs*(A.dot(vs)),axis=0)\n",
    "print(min(a),max(a))\n",
    "print(np.linalg.eigh(A)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "I would probably compare $[A{\\bf x}]_\\beta$ with $(c_0\\lambda_0, \\ldots, c_4\\lambda_4)^\\top$  \n",
    "instead of comparing $A{\\bf x}$ $c_0\\lambda_0{\\bf u}_0 + \\cdots + c_4\\lambda_4{\\bf u}_4$.  \n",
    "```python\n",
    "A = np.array([[0,1,0,0,0],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [0,0,0,1,0]])\n",
    "vals,vecs = LA.eigh(A)\n",
    "x = np.random.randn(5)\n",
    "c = vecs.T.dot(x)\n",
    "\n",
    "print(\"x =\", x)\n",
    "print(\"[x]_beta =\", c)\n",
    "print(\"|x|^2, |[x]_beta|^2 =\", np.sum(x**2), np.sum(c**2))\n",
    "print(\"---\")\n",
    "print(\"[Ax]_beta =\", vecs.T.dot(A.dot(x)))\n",
    "print(\"ci lambda i =\", c*vals)\n",
    "print(\"---\")\n",
    "print(\"xAx =\", x.dot(A.dot(x)))\n",
    "print(\"sum of ci^2 lambda i =\", np.sum(c**2 * vals))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 4\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[1,-1,0,0,0],\n",
    "              [-1,2,-1,0,0],\n",
    "              [0,-1,2,-1,0],\n",
    "              [0,0,-1,2,-1],\n",
    "              [0,0,0,-1,1]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(a)\n",
    "Pick a random vector ${\\bf x} = (x_0,x_1,x_2,x_3,x_4)^\\top$.  \n",
    "Check that \n",
    "$${\\bf x}^\\top A{\\bf x} = \\sum_{\\substack{i<j \\\\ (A)_{ij} = -1}}(x_i - x_j)^2.$$  \n",
    "For convenience, we call this value as $R({\\bf x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.array([[1,-1,0,0,0],\n",
    "              [-1,2,-1,0,0],\n",
    "              [0,-1,2,-1,0],\n",
    "              [0,0,-1,2,-1],\n",
    "              [0,0,0,-1,1]])\n",
    "vs = np.random.randn(5,1)\n",
    "vs = vs / np.linalg.norm(vs, axis=0)\n",
    "a=np.sum(vs*(A.dot(vs)),axis=0)\n",
    "a\n",
    "b=np.matrix(np.power(vs-vs.T,2))\n",
    "b=np.diagonal(b,offset=1).sum(axis=0)\n",
    "\n",
    "np.isclose(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "- `np.matrix` is not recommended by the NumPy community since it is no more well-maintained.\n",
    "- the code can be simplier as follows.\n",
    "\n",
    "```python\n",
    "A = np.array([[1,-1,0,0,0],\n",
    "              [-1,2,-1,0,0],\n",
    "              [0,-1,2,-1,0],\n",
    "              [0,0,-1,2,-1],\n",
    "              [0,0,0,-1,1]])\n",
    "\n",
    "x = np.random.randn(5)\n",
    "a = x.dot(A.dot(x))\n",
    "\n",
    "diff_square = (x[:,np.newaxis] - x)**2\n",
    "mask = (A == -1)\n",
    "b = diff_square[mask].sum() / 2\n",
    "\n",
    "print(a, b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(b)\n",
    "Pick 1000000 random vector ${\\bf x}$ of length 1 in $\\mathbb{R}^5$.  \n",
    "Find the one ${\\bf u}_0$ that achieve the minimum $R({\\bf x})$.  \n",
    "Can you guess the correct ${\\bf u}_0$ by the identity in 4(a)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.array([[1,-1,0,0,0],\n",
    "              [-1,2,-1,0,0],\n",
    "              [0,-1,2,-1,0],\n",
    "              [0,0,-1,2,-1],\n",
    "              [0,0,0,-1,1]])\n",
    "vs = np.random.randn(5,1000000)\n",
    "vs = vs / np.linalg.norm(vs, axis=0)\n",
    "a=np.sum(vs*(A.dot(vs)),axis=0)\n",
    "np.where(a == a.min()) \n",
    "minvs=vs[:,np.where(a == a.min())]\n",
    "v=np.array(vs[:,np.where(a == a.min())])[:,0,:]\n",
    "b=np.sum(v*(A.dot(v)),axis=0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0=minvs[:,:,0][:,0]\n",
    "a=np.sum(u0*(A.dot(u0)),axis=0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Since we are only interest in one vector that achieves the minimum  \n",
    "but not all vectors that achieve the minimum,  \n",
    "we may do `np.argmin` instead of `np.where(a = a.min())` .  \n",
    "\n",
    "Also, you did not answer what is the vector realizing the minimum.  \n",
    "According to the equation in (a),  \n",
    "the right-hand side has minimum achieved by ${\\bf x} = (x_0,\\ldots,x_4)^\\top$  \n",
    "with $x_0=x_1$, $\\ldots$, and $x_3=x_4$.\n",
    "\n",
    "See sample below.  \n",
    "\n",
    "```python\n",
    "A = np.array([[1,-1,0,0,0],\n",
    "              [-1,2,-1,0,0],\n",
    "              [0,-1,2,-1,0],\n",
    "              [0,0,-1,2,-1],\n",
    "              [0,0,0,-1,1]])\n",
    "vs = np.random.randn(5,1000000)\n",
    "vs = vs / np.linalg.norm(vs, axis=0)\n",
    "Rs = np.sum(vs*(A.dot(vs)),axis=0)\n",
    "ind = Rs.argmin()\n",
    "\n",
    "print(Rs[ind])\n",
    "print(vs[:,ind])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
