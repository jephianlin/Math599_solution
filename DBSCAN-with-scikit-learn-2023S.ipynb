{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN with scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_mtx(X, Y):\n",
    "    X_col = X[:, np.newaxis, :]\n",
    "    Y_row = Y[np.newaxis, :, :]\n",
    "    dist = np.linalg.norm(X_col - Y_row, axis=-1)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "```python\n",
    "from sklearn.cluster import DBSCAN\n",
    "model = DBSCAN(<parameters>)\n",
    "y_new = model.fit_predict(X)\n",
    "```\n",
    "\n",
    "[Official Reference](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- `eps`: the $\\epsilon$ used for finding neighborhood\n",
    "- `min_samples`: a sample is considered as a core sample if its $\\epsilon$-ball contains at least `min_sample` samples (including itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "- `core_sample_indices_`: an array of shape `(n_core_samples,)` that stores the indices of the core samples\n",
    "- `components_`: an array of shape `(n_core_samples, n_features)` that stores the core samples as rows\n",
    "- `labels_`: an array of shape `(n_samples,)` that stores the label of each sample, where `-1` stands for noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "mu1 = np.array([2.5,0])\n",
    "cov1 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "mu2 = np.array([-2.5,0])\n",
    "cov2 = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Apply the DBSCAN algorithm to `X` with the default setting and get the prediction `y_new` .  \n",
    "Plot the points (rows) in `X` with `c=y_new` .  \n",
    "Print `model.core_sample_indices_.shape` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "model = DBSCAN()\n",
    "\n",
    "mu1 = np.array([2.5,0])\n",
    "cov1 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "mu2 = np.array([-2.5,0])\n",
    "cov2 = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "y_new = model.fit_predict(X)\n",
    "\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.scatter(*X.T, c=y_new)\n",
    "plt.scatter(*model.components_.T, c='r', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(2)\n",
    "y_KMeans = model.fit_predict(X)\n",
    "plt.axis('equal')\n",
    "plt.scatter(*X.T, c=y_KMeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veronica \n",
    "\n",
    "You forgot to answer this one.\n",
    "```python\n",
    "print(model.core_sample_indices_.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Apply the DBSCAN algorithm to `X` with `eps=1` and get the prediction `y_new` .  \n",
    "Plot the points (rows) in `X` with `c=y_new` .  \n",
    "Print `model.core_sample_indices_.shape` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = DBSCAN(eps=1)\n",
    "y_DBSCAN = model.fit_predict(X)\n",
    "plt.axis('equal')\n",
    "plt.scatter(*X.T, c=y_DBSCAN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veronica \n",
    "\n",
    "You forgot to answer this one.\n",
    "```python\n",
    "print(model.core_sample_indices_.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1(c)\n",
    "Apply the DBSCAN algorithm to `X` with `min_samples=10` and get the prediction `y_new` .  \n",
    "Plot the points (rows) in `X` with `c=y_new` .  \n",
    "Print `model.core_sample_indices_.shape` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "\n",
    "eps, min_samples = 1, 10\n",
    "\n",
    "dist = dist_mtx(X, X)\n",
    "adj = (dist <= eps) \n",
    "core_mask = (adj.sum(axis=1) >= min_samples) \n",
    "cores = X[core_mask]\n",
    "noise_mask = np.all(dist_mtx(X, cores) > eps, axis=1) \n",
    "noises = X[noise_mask]\n",
    "\n",
    "\n",
    "\n",
    "y_cores = model.fit_predict(cores)\n",
    "plt.axis('equal')\n",
    "plt.scatter(*X.T, c='y')\n",
    "plt.scatter(*cores.T, c=y_cores)\n",
    "plt.scatter(*noises.T, c='purple', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "model = DBSCAN(min_samples=10)\n",
    "y = model.fit_predict(X)\n",
    "plt.scatter(*X.T, c=y)\n",
    "print(model.core_sample_indices_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(d)\n",
    "Finding an appropriate `eps` is the main task for the DBSCAN algorithm.  \n",
    "Let `dist` be the distance matrix between rows in `X` .  \n",
    "The code below find the average of the distances between one sample to its $k$-th nearest sample.\n",
    "```python\n",
    "k = 10\n",
    "sort_dist = dist.copy()\n",
    "sort_dist.partition(k)\n",
    "sort_dist[:,:k+1].max(axis=1).mean()\n",
    "```\n",
    "This can be a reference for the choice of `eps` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "k = 2\n",
    "sort_dist = dist.copy()\n",
    "sort_dist.partition(k)\n",
    "sort_dist[:,:k+1].max(axis=1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veronica \n",
    "\n",
    "From the question, `k` should be changed to 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(e)\n",
    "Finding an appropriate `min_samples` is another task for the DBSCAN algorithm.  \n",
    "Let `dist` be the distance matrix between rows in `X` .\n",
    "The code below generate the histogram of the number of neighbors inside the $\\epsilon$-balls centered at each sample.\n",
    "```python\n",
    "eps = 0.5\n",
    "n_nbrs = np.sum(dist < eps, axis=1)\n",
    "plt.hist(n_nbrs)\n",
    "```\n",
    "This can be a reference for the choice of `min_samples` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "eps = 0.247\n",
    "n_nbrs = np.sum(dist < eps, axis=1)\n",
    "plt.hist(n_nbrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veronica \n",
    "\n",
    "From the question, `eps` should be changed to 0.5 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_iris = iris.target\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Plot the points (rows) in `X` with `c=y_iris` .  \n",
    "(Each row is in $\\mathbb{R}^4$.  \n",
    "Just pick arbitrary two coordinates to plot the points.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "A=np.zeros([2,150])\n",
    "A[0]=X.T[0]\n",
    "A[1]=X.T[1]\n",
    "A=A.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.scatter(*A.T, c=y_iris)###chose row 0,1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veronica \n",
    "\n",
    "You can just write the following code.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "plt.axis(\"equal\")\n",
    "plt.scatter(X[:,1], X[:,2], c=y_iris)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "Apply the DBSCAN algorithm to `X` with the default setting and get the prediction `y_new` .  \n",
    "Plot the points (rows) in `X` with `c=y_new` .  \n",
    "(Each row is in $\\mathbb{R}^4$.  \n",
    "Just pick arbitrary two coordinates to plot the points.)  \n",
    "Try your best to find appropriate `eps` and `min_samples` so that the results is similar to `y_iris` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "sort_dist = dist.copy()\n",
    "sort_dist.partition(k)\n",
    "eps=sort_dist[:,:k+1].max(axis=1).mean()\n",
    "eps\n",
    "n_nbrs = np.sum(dist < eps, axis=1)\n",
    "xr=plt.hist(n_nbrs)\n",
    "print(xr)\n",
    "\n",
    "\n",
    "min_samples = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 3\n",
    "Let  \n",
    "```python\n",
    "from PIL import Image\n",
    "img = Image.open('incrediville-side.jpg')\n",
    "arr = np.array(img.resize((int(img.size[0]/30), int(img.size[1]/30))))\n",
    "m,n,c = arr.shape\n",
    "X = arr.reshape(-1,3)\n",
    "```\n",
    "Decide appropriate `eps` and `min_samples` so that  \n",
    "```python\n",
    "img = (y_new == 0).reshape(m, n)\n",
    "plt.imshow(img, cmap='Greys')\n",
    "```\n",
    "gives good image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "from PIL import Image\n",
    "img = Image.open('incrediville-side.jpg')\n",
    "arr = np.array(img.resize((int(img.size[0]/30), int(img.size[1]/30))))\n",
    "m,n,c = arr.shape\n",
    "X = arr.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = dist_mtx(X, X)\n",
    "\n",
    "\n",
    "k = 3\n",
    "sort_dist = dist.copy()\n",
    "sort_dist.partition(k)\n",
    "eps=sort_dist[:,:k+1].max(axis=1).mean()\n",
    "\n",
    "\n",
    "n_nbrs = np.sum(dist < eps, axis=1)\n",
    "plt.hist(n_nbrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = (dist <= eps) \n",
    "core_mask = (adj.sum(axis=1) >= min_samples) \n",
    "cores = X[core_mask]\n",
    "noise_mask = np.all(dist_mtx(X, cores) > eps, axis=1) \n",
    "noises = X[noise_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = model.fit_predict(X)\n",
    "img = (y_new == 0).reshape(m, n)\n",
    "plt.imshow(img, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 4\n",
    "Let  \n",
    "```python\n",
    "mu1 = np.array([2.5,0])\n",
    "cov1 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "mu2 = np.array([-2.5,0])\n",
    "cov2 = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "\n",
    "model = DBSCAN()\n",
    "y_new = model.fit_predict(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(a)\n",
    "Print `model.core_sample_indices_.shape` and `model.components_.shape` .  \n",
    "Confirm that `X[model.core_sample_indices_]` and `model.components` are the same.  \n",
    "Can you tell how many points that are not noise nor core?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = np.array([2.5,0])\n",
    "cov1 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "mu2 = np.array([-2.5,0])\n",
    "cov2 = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "\n",
    "model = DBSCAN()\n",
    "y_new = model.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DBSCAN()\n",
    "y_new = model.fit_predict(X)\n",
    "\n",
    "print(X.shape)\n",
    "model = DBSCAN()\n",
    "model.fit(X)\n",
    "print(model.components_.shape)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y_new)\n",
    "print(model.core_sample_indices_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian\n",
    "\n",
    "So the number of samples that is not a core nor a noise can be obtained by the following.\n",
    "```python\n",
    "n_sample = X.shape[0]\n",
    "n_core = model.core_sample_indices_.shape[0]\n",
    "n_noise = np.sum(model.labels_ == -1)\n",
    "n_sample - n_core - n_noise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(b)\n",
    "Plot the points (rows) in `X` with `c=y_new` .  \n",
    "Plot the core samples with `c='r'` and `s=10` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"equal\")\n",
    "plt.scatter(*X.T, c=y_new)\n",
    "plt.scatter(X[model.core_sample_indices_,0], X[model.core_sample_indices_,1], c='r', s=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(c)\n",
    "Use `model.labels_` to find out the noise samples.  \n",
    "Adding upon your previous figure, plot the core samples with `c='k'`, `s=100`, and `marker='x'`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = X[model.labels_ == -1]   #noise samples\n",
    "plt.axis(\"equal\")\n",
    "plt.scatter(*X.T, c=y_new)\n",
    "plt.scatter(X[model.core_sample_indices_,0], X[model.core_sample_indices_,1], c='k', s=100, marker='x')\n",
    "plt.scatter(*noise.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian\n",
    "\n",
    "```python\n",
    "plt.axis(\"equal\")\n",
    "plt.scatter(X[:,0], X[:,1], c=y_new)\n",
    "plt.scatter(X[model.core_sample_indices_,0], X[model.core_sample_indices_,1], c='r', s=10)\n",
    "plt.scatter(X[model.labels_==-1,0], X[model.labels_==-1,1], c='k', s=100, marker='x')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5\n",
    "Let  \n",
    "```python\n",
    "X = 5 * np.random.randn(1000,2)\n",
    "lengths = np.linalg.norm(X, axis=1)\n",
    "band1 = (lengths > 1) & (lengths <2)  \n",
    "band2 = (lengths > 3) & (lengths <4)  \n",
    "X = X[band1 | band2, :]\n",
    "```\n",
    "Apply the DBSCAN algorithm to `X` with `eps=1`  \n",
    "(or other settings that you like)  \n",
    "and get the prediction `y_new` .  \n",
    "Plot the points (rows) in `X` with `c=y_new` .  \n",
    "Is it a good clustering?  \n",
    "For this data, would you choose DBSCAN or KMeans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 5 * np.random.randn(1000,2)\n",
    "lengths = np.linalg.norm(X, axis=1)\n",
    "band1 = (lengths > 1) & (lengths <2)  \n",
    "band2 = (lengths > 3) & (lengths <4)  \n",
    "X = X[band1 | band2, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DBSCAN(eps=1)\n",
    "y_DBSCAN = model.fit_predict(X)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.scatter(*X.T, c=y_DBSCAN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(2)\n",
    "y_new = model.fit_predict(X)\n",
    "\n",
    "X_test = np.random.rand(1000, 2) * 8 - np.array([4,4])\n",
    "y_test_new = model.predict(X_test)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.scatter(*X_test.T, c=y_test_new, s=10, alpha=0.1)\n",
    "plt.scatter(*X.T, c=y_new)\n",
    "plt.scatter(*model.cluster_centers_.T, c='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
