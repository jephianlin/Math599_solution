{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "**Input:**  \n",
    "- `X`: an array of shape `(N,d)` whose rows are samples and columns are features\n",
    "- `y`: the labels of shape `(N,)`\n",
    "- `k`: Numbers of neighbors (including self) to vote\n",
    "- `algorithm`: `'brute'`, `'ball_tree'`, or `'kd_tree'`\n",
    "\n",
    "**Output:**  \n",
    "A tuple `(predict, k_nearest_neighbors)`.  \n",
    "- `predict`: a function that takes data `X_sample` and output their predicted labels\n",
    "- `k_nearest_neighbors`: a function that takes data `X_sample` and return an array of shape `(X_sample_height, k)` that stores the indices of the nearest neighbors in `X` for each row in `X_sample`\n",
    "\n",
    "**Steps:**\n",
    "1. If `algorithm==\"brute\"`, create the function `k_nearest_neighbors` by the distance matrix.  \n",
    "2. If `algorithm==\"ball_tree\"` or `algorithm==\"kd_tree\"`, create the function `k_nearest_neighbors` by `sklearn.neighbors.NearestNeighbors` with the corresponding algorithm.\n",
    "3. Create the function `predict` that executes the following steps:\n",
    "    1. Input `X_sample` .\n",
    "    2. Let `nbrhoods = k_nearest_neighbors(X_sample)` .  \n",
    "    3. Let `votes = y[nbrhoods]` .\n",
    "    4. Calculate the most frequent label in each row of `votes` and store the results in `y_new` .\n",
    "    5. Return `y_new` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode\n",
    "Translate the algorithm into the pseudocode.  \n",
    "This helps you to identify the parts that you don't know how to do it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. 這個程式碼定義了一個名為 knn 的函式，它接受四個參數：X、y、algorithm 和 k。\n",
    "    2. 如果 algorithm 參數為 \"brute\"，則使用 dist_mtx 函式計算距離矩陣，並使用 get_k_nearest_indices 函式找到每個樣本的 k 個最近Neighbors。\n",
    "    3. 如果 algorithm 參數為 \"ball_tree\" 或 \"kd_tree\"，則使用 sklearn.neighbors.NearestNeighbors 類創建 k_nearest_neighbors 函式。\n",
    "    4.knn 函式還義了一個名為 predict 的子函式，它接受一個樣本 X_sample，使用 k_nearest_neighbors 函式找到其 k 個最近Neighbors，使用 y 數組中的標籤計算最常見的標籤，並返回預測的標籤。\n",
    "    5.最後，knn 函式返回 predict 和 k_nearest_neighbors 函式的元組。 dist_mtx 函式計算兩個數組之間的歐幾里德距離矩陣，get_k_nearest_indices 函式返回每個樣本的 個最近Neighbors的索引，calculate_most_frequent_label 函式計算每個樣本的最常見標籤。    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "\n",
    "def dist_mtx(X, Y):     #Defines how the distance is calculated\n",
    "    X_col = X[:,np.newaxis,:]\n",
    "    Y_row = Y[np.newaxis,:,:]\n",
    "    diff = X_col - Y_row\n",
    "    dist = np.linalg.norm(diff, axis=-1)\n",
    "    return dist\n",
    "\n",
    "def get_y(kneighbors, y):   #Calculate the \"most neighbors\" in the vicinity\n",
    "    return stats.mode(y[kneighbors], axis=1).mode.reshape(kneighbors.shape[0])\n",
    "\n",
    "def knn(X, y, algorithm, k):\n",
    "    if algorithm == 'brute':\n",
    "        def k_nearest_neighbors(X_sample): \n",
    "            dist = dist_mtx(X_sample, X)\n",
    "            argp = dist.argpartition(k-1, axis=1)\n",
    "            return argp[:,:k]\n",
    "        \n",
    "        def predict(X_sample):\n",
    "            k_neighbors = k_nearest_neighbors(X_sample)\n",
    "            return get_y(k_neighbors, y)\n",
    "            \n",
    "    elif algorithm in ['ball_tree', 'kd_tree']:\n",
    "        def k_nearest_neighbors(X_sample):\n",
    "            nbr = NearestNeighbors(n_neighbors=k, algorithm=algorithm)\n",
    "            nbr.fit(X)\n",
    "            return nbr.kneighbors(X_sample, return_distance=False)\n",
    "        \n",
    "        def predict(X_sample):\n",
    "            k_neighbors = k_nearest_neighbors(X_sample)\n",
    "            return get_y(k_neighbors, y)\n",
    "\n",
    "    return predict, k_nearest_neighbors\n",
    "\n",
    "#Anothor Solution:\n",
    "# def knn(X, y, k, algorithm):\n",
    "#     if algorithm == \"brute\":\n",
    "#         # create k_nearest_neighbors function using distance matrix\n",
    "#         def k_nearest_neighbors(X_sample):\n",
    "#             # calculate distance matrix between X and X_sample\n",
    "#             dist_matrix = calculate_distance_matrix(X, X_sample)\n",
    "#             # get indices of k nearest neighbors for each sample in X_sample\n",
    "#             k_nearest_indices = get_k_nearest_indices(dist_matrix, k)\n",
    "#             return k_nearest_indices\n",
    "\n",
    "#     elif algorithm == \"ball_tree\" or algorithm == \"kd_tree\":\n",
    "#         # create k_nearest_neighbors function using sklearn.neighbors.NearestNeighbors\n",
    "#         from sklearn.neighbors import NearestNeighbors\n",
    "#         nbrs = NearestNeighbors(n_neighbors=k, algorithm=algorithm).fit(X)\n",
    "#         def k_nearest_neighbors(X_sample):\n",
    "#             # get indices of k nearest neighbors for each sample in X_sample\n",
    "#             _, k_nearest_indices = nbrs.kneighbors(X_sample)\n",
    "#             return k_nearest_indices\n",
    "\n",
    "#     # create predict function\n",
    "#     def predict(X_sample):\n",
    "#         # get indices of k nearest neighbors for each sample in X_sample\n",
    "#         nbrhoods = k_nearest_neighbors(X_sample)\n",
    "#         # get labels of k nearest neighbors for each sample in X_sample\n",
    "#         votes = y[nbrhoods]\n",
    "#         # calculate most frequent label for each row in votes\n",
    "#         y_new = calculate_most_frequent_label(votes)\n",
    "#         return y_new\n",
    "\n",
    "#     return predict, k_nearest_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Take some sample data from [KNeighborsClassifier-with-scikit-learn](KNeighborsClassifier-with-scikit-learn.ipynb) and check if your code generates similar outputs with the existing packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Name of the data\n",
    "Description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mu1 = np.array([2.5,0])\n",
    "cov1 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "\n",
    "mu2 = np.array([-2.5,0])\n",
    "cov2 = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "y = np.array([0]*100 + [1]*100)\n",
    "\n",
    "X_sample = np.random.uniform(low=-5, high=5, size=(1000,2))\n",
    "plt.scatter(*X.T, c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict, k_nearest_neighbors  = knn(X, y, 'brute', 2)\n",
    "y_new = predict(X_sample)\n",
    "plt.figure(figsize=(6, 6)) \n",
    "plt.subplot(311).set_title('brute')\n",
    "plt.scatter(*X_sample.T, c=y_new)\n",
    "\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'ball_tree', 2)\n",
    "y_new = predict(X_sample)\n",
    "plt.subplot(312).set_title('ball_tree')\n",
    "plt.scatter(*X_sample.T, c=y_new)\n",
    "\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'kd_tree', 2)\n",
    "y_new = predict(X_sample)\n",
    "plt.subplot(313).set_title('kd_tree')\n",
    "plt.scatter(*X_sample.T, c=y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X, y)\n",
    "\n",
    "y_new = model.predict(X_sample)\n",
    "plt.figure(figsize=(6, 2))\n",
    "plt.suptitle('sklearn')\n",
    "plt.scatter(*X_sample.T, c=y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*20 + [1]*20)\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Train a $k$-nearest neighbors classification model by `X` and `y` .  \n",
    "Make a prediction of `X_sample` by:  \n",
    "1. your code with different algorithm settings\n",
    "2. `sklearn.neighbors.KNeighborsClassifier`\n",
    "\n",
    "The results should be the same.  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*20 + [1]*20)\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def k_nearest_neighbors(X, y, k, algorithm):\n",
    "    if algorithm == 'brute':\n",
    "        def knn(X_sample):\n",
    "            distances = np.sqrt(((X - X_sample[:, np.newaxis])**2).sum(axis=2))\n",
    "            k_nearest = np.argsort(distances, axis=1)[:, :k]\n",
    "            return k_nearest\n",
    "        \n",
    "    elif algorithm == 'ball_tree' or algorithm == 'kd_tree':\n",
    "        nn = NearestNeighbors(n_neighbors=k, algorithm=algorithm)\n",
    "        nn.fit(X)\n",
    "        \n",
    "        def knn(X_sample):\n",
    "            return nn.kneighbors(X_sample, return_distance=False)\n",
    "        \n",
    "    return knn\n",
    "\n",
    "def predict(X_sample, X, y, k, algorithm):\n",
    "    knn_func = k_nearest_neighbors(X, y, k, algorithm)\n",
    "    nbrhoods = knn_func(X_sample)\n",
    "    votes = y[nbrhoods]\n",
    "    \n",
    "    y_new = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=votes)\n",
    "    return y_new, nbrhoods\n",
    "\n",
    "y_new, nbrhoods = predict(X_sample, X, y, k=3, algorithm='brute')\n",
    "print(y_new)\n",
    "print(nbrhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3, algorithm='brute')\n",
    "knn.fit(X, y)\n",
    "\n",
    "y_new = knn.predict(X_sample)\n",
    "nbrhoods = knn.kneighbors(X_sample, return_distance=False)\n",
    "print(y_new)\n",
    "print(nbrhoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> The result of the above inspection can be obtained they are same and true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veronica  \n",
    "\n",
    "I recommend using the following code since we don't have to print all the values to check whether the two outputs are the same or not.\n",
    "\n",
    "Another method:\n",
    "\n",
    "```python\n",
    "y_new, nbrhoods = predict(X_sample, X, y, k=3, algorithm='brute')\n",
    "y_new_knn = knn.predict(X_sample)\n",
    "nbrhoods_knn = knn.kneighbors(X_sample, return_distance=False)\n",
    "print(y_new.all() == y_new_knn.all())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Let `y_new` be the prediction of `X_sample` in the previous question. \n",
    "Plot the points (rows) in `X` with `c=y` .  \n",
    "Plot the points (rows) in `X_sample` with `c=y_new` and `alpha=0.1` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot points in X with c=y\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "# Plot points in X_sample with c=y_new and alpha=0.1\n",
    "plt.scatter(X_sample[:, 0], X_sample[:, 1], c=y_new, alpha=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X.T, c=y, label=\"Training data\", marker=\"*\", s=60)\n",
    "plt.scatter(*X_sample.T, c=y_new, alpha=0.1, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please continue with the previous question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Let  \n",
    "```python\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "```  \n",
    "and let `k_nearest_neighbors` be one of the output of your function.  \n",
    "The results of `k_nearest_neighbors(X_sample)` should be the same as `model.kneighbors(X_sample, return_distance=False)` .  \n",
    "(The corresponding rows contains the same collection of elements, but might be in different order.)  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define X_sample, X, and y\n",
    "X = np.array([[0, 0], [1, 1], [1, 0], [0, 1]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "X_sample = np.array([[0.5, 0.5], [0.2, 0.2]])\n",
    "\n",
    "#Define k_nearest_neighbors and predict functions\n",
    "def k_nearest_neighbors(X, y, k, algorithm):\n",
    "    if algorithm == 'brute':\n",
    "        def knn(X_sample):\n",
    "            distances = np.sqrt(((X - X_sample[:, np.newaxis])**2).sum(axis=2))\n",
    "            k_nearest = np.argsort(distances, axis=1)[:, :k]\n",
    "            return k_nearest\n",
    "    elif algorithm == 'ball_tree' or algorithm == 'kd_tree':\n",
    "        nn = NearestNeighbors(n_neighbors=k, algorithm=algorithm)\n",
    "        nn.fit(X)\n",
    "        def knn(X_sample):\n",
    "            return nn.kneighbors(X_sample, return_distance=False)\n",
    "    return knn\n",
    "\n",
    "def predict(X_sample, X, y, k, algorithm):\n",
    "    knn_func = k_nearest_neighbors(X, y, k, algorithm)\n",
    "    nbrhoods = knn_func(X_sample)\n",
    "    votes = y[nbrhoods]\n",
    "    y_new = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=votes)\n",
    "    return y_new, nbrhoods\n",
    "\n",
    "# Get predictions with brute-force algorithm\n",
    "y_new, nbrhoods = predict(X_sample, X, y, k=3, algorithm='brute')\n",
    "\n",
    "# Plot points in X with c=y\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "# Plot points in X_sample with c=y_new and alpha=0.1\n",
    "plt.scatter(X_sample[:, 0], X_sample[:, 1], c=y_new, alpha=0.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X, y)\n",
    "print('Check if this is true:',(nbrhoods==model.kneighbors(X_sample, return_distance=False)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> The result of the above inspection can be obtained this is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veronica  \n",
    "\n",
    "In my opinion, you don't have to redefine the `k_nearest_neighbors` again since you have done once again.\n",
    "\n",
    "It may be redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2)\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n))\n",
    "xx = np.zeros((frames, m, n))\n",
    "count =  0\n",
    "for i in range(m-2):\n",
    "    for j in range(n-2):\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Run  \n",
    "```python\n",
    "plt.imshow(oo[i], cmap=\"Greys\")\n",
    "```\n",
    "with different `i` .  \n",
    "Guess what is the meaning of `oo` and `xx` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2)\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n))\n",
    "xx = np.zeros((frames, m, n))\n",
    "count =  0\n",
    "\n",
    "for i in range(m-2):\n",
    "    for j in range(n-2):\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        ax = plt.subplot2grid((6,6), (i,j))\n",
    "        ax.imshow(oo[i*6+j], cmap=\"Greys\")\n",
    "        \n",
    "print('oo is a 36 images set, an o-like object in each image from left to right, up to down with step 1')\n",
    "print('xx is a 36 images set, an x-like object in each image from left to right, up to down with step 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "Train a $k$-nearest neighbors classification model by `X` an `y` .  \n",
    "Make a prediction `y_new` for the training data `X` .  \n",
    "What is the outcome?  \n",
    "Can you give a reason to this phenomenon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X, y, k, algorithm):\n",
    "    def k_nearest_neighbors(X_sample):\n",
    "        if algorithm == \"brute\":\n",
    "            dist = dist_mtx(X_sample, X)\n",
    "            argp = dist.argpartition(k-1, axis=1)\n",
    "            return argp[:,:k]\n",
    "        \n",
    "        elif algorithm == \"ball_tree\" or algorithm == \"kd_tree\":\n",
    "            nbr = NearestNeighbors(n_neighbors=k, algorithm=algorithm)\n",
    "            nbr.fit(X)\n",
    "            return nbr.kneighbors(X_sample, return_distance=False)\n",
    "\n",
    "    def predict(X_sample):\n",
    "        k_neighbors = k_nearest_neighbors(X_sample)\n",
    "        return get_y(k_neighbors, y)\n",
    "\n",
    "    return predict, k_nearest_neighbors\n",
    "\n",
    "for k in range(1, 10):\n",
    "    predict, k_nearest_neighbors = knn(X, y, k, 'brute')\n",
    "    y_new = predict(X) #(72,)\n",
    "    \n",
    "    print(\"k = \",k,\"\\n\",y_new,\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> When k = 1, the prediction must be correct, because you use yourself to predict, y = y_new.\n",
    "\n",
    "=> Different $k$ will have different prediction results, because different points are circled, so the decision-making results will be different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
