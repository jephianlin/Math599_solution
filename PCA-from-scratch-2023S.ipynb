{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "**Input:**  \n",
    "- `X`: an array of shape `(N,d)` whose rows are samples and columns are features\n",
    "- `r`: target dimension\n",
    "\n",
    "**Output:**\n",
    "- an array of shape `(N, r)`  \n",
    "\n",
    "**Steps:**\n",
    "1. Shift $X$ so that the rows of $X$ are centered at the origin.  \n",
    "2. Let $C = \\frac{1}{N}X^\\top X$.  \n",
    "3. Suppose ${\\bf u}_1,\\ldots, {\\bf u}_d$ form an orthonormal eigenbasis of $C$ corresponding to the eigenvalues $\\lambda_1\\geq\\cdots\\geq\\lambda_d$.  Let $U$ be the matrix whose columns are ${\\bf u}_1,\\ldots, {\\bf u}_r$.  \n",
    "4. Return $XU$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode\n",
    "Translate the algorithm into the pseudocode.  \n",
    "This helps you to identify the parts that you don't know how to do it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. X = X - X.mean(axis=0)\n",
    "    2. N,d = X.shape\n",
    "       C = (X.T.dot(X))/N\n",
    "    3. vals,vecs = np.linalg.eigh(C)\n",
    "       vals = vals[::-1]\n",
    "       vecs = vecs[:,::-1]\n",
    "       U = vecs[:,:r]\n",
    "    4. return X@U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCAscratch(X,r): # X is a set of given data, r is our target dimension.\n",
    "    X = X - X.mean(axis=0) # Shift X so that the rows of X are centered at the origin.\n",
    "    N,d = X.shape # X is an array of shape (N,d), and we need the number of N to calculate C.\n",
    "    C = (X.T.dot(X))/N # C is a convariance matrix.\n",
    "    vals,vecs = np.linalg.eigh(C) # Get the eigenvalues and eigenvectors of C.\n",
    "    vals = vals[::-1] # Make eigenvalues from large to small.\n",
    "    vecs = vecs[:,::-1] # Make eigenvectors from large to small.\n",
    "    U = vecs[:,:r] # U only need the first r columns of vecs matrix.\n",
    "    return X@U # Return XU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Take some sample data from [PCA-with-scikit-learn](PCA-with-scikit-learn.ipynb) and check if your code generates similar outputs with the existing packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Name of the data\n",
    "X = np.genfromtxt('hidden_text.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('hidden_text.csv', delimiter=',') \n",
    "# I also tried the load_digits, but just too difficult to check the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### results with your code\n",
    "print(PCAscratch(X,2))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.axis('equal')\n",
    "plt.scatter(*PCAscratch(X,2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with scikit learn\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(2)\n",
    "X_new = model.fit_transform(X)\n",
    "print(X_new)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.axis('equal')\n",
    "plt.scatter(*X_new.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check : å…©è€…å·®åˆ¥å°±æ˜¯ä¸Šä¸‹é¡›å€’ï¼Œæ‰€ä»¥ä»–å€‘æ˜¯å¾ˆç›¸ä¼¼çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "The center of rows of $X$ (before shift) is supposed to be `model.mean_` .  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('hidden_text.csv', delimiter=',')\n",
    "\n",
    "r = 2\n",
    "X = X - X.mean(axis=0) # Shift X so that the rows of X are centered at the origin.\n",
    "N,d = X.shape # X is an array of shape (N,d), and we need the number of N to calculate C.\n",
    "C = (X.T.dot(X))/N # C is a convariance matrix.\n",
    "vals,vecs = np.linalg.eigh(C) # Get the eigenvalues and eigenvectors of C.\n",
    "vals = vals[::-1] # Make eigenvalues from large to small.\n",
    "vecs = vecs[:,::-1] # Make eigenvectors from large to small.\n",
    "U = vecs[:,:r] # U only need the first r columns of vecs matrix.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(r)\n",
    "X_new = model.fit_transform(X)\n",
    "\n",
    "Ans = np.allclose(X.mean(axis=0),model.mean_) \n",
    "# If center of rows of X (before shift) and model.mean_ are same (very close), Ans will equal True.\n",
    "print(Ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "The matrix $U^\\top$ is supposed to be `model.components_` .  \n",
    "(Up to some negations.)  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('hidden_text.csv', delimiter=',')\n",
    "\n",
    "r = 2\n",
    "X = X - X.mean(axis=0) # Shift X so that the rows of X are centered at the origin.\n",
    "N,d = X.shape # X is an array of shape (N,d), and we need the number of N to calculate C.\n",
    "C = (X.T.dot(X))/N # C is a convariance matrix.\n",
    "vals,vecs = np.linalg.eigh(C) # Get the eigenvalues and eigenvectors of C.\n",
    "vals = vals[::-1] # Make eigenvalues from large to small.\n",
    "vecs = vecs[:,::-1] # Make eigenvectors from large to small.\n",
    "U = vecs[:,:r] # U only need the first r columns of vecs matrix.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(r)\n",
    "X_new = model.fit_transform(X)\n",
    "\n",
    "Ans = True # Suppose Ans is True at first.\n",
    "# å› ç‚ºæ¯å€‹ä¸»æˆåˆ†(å‘é‡)å¯ä»¥æ˜¯è² çš„ä¹Ÿå¯ä»¥æ˜¯æ­£çš„ï¼Œåªè¦æ˜¯åŒä¸€æ¢ç·šä¸Šå°±å¥½äº†ã€‚\n",
    "# æ‰€ä»¥æˆ‘å€‘åœ¨åšæ¯”è¼ƒçš„æ™‚å€™ï¼Œè¦æŠŠä¹˜ä¸Šä¸€å€‹è² è™Ÿå°±ç›¸ç­‰çš„æƒ…æ³ä¹Ÿè€ƒæ…®é€²å»ã€‚ (é€™æ®µä¸å¤ªæœƒç”¨è‹±æ–‡è¬›)\n",
    "for i in range(r) :\n",
    "    if np.allclose(U.T[i],model.components_[i])| np.allclose(-U.T[i],model.components_[i]) == False :\n",
    "        Ans = False # å¦‚æœæœ‰ä»»ä½•ä¸€å€‹ä¸»æˆåˆ† (U.Tçš„æ©«åˆ—) ä¸ç¬¦åˆä¸Šè¿°æƒ…æ³ï¼Œå°±ä»£è¡¨UTä¸æ˜¯model.components_ï¼ŒæŠŠAnsæ”¹Falseç„¶å¾Œbreakè¿´åœˆã€‚\n",
    "        break\n",
    "# å¦‚æœè·‘å®Œè¿´åœˆ (æ¯”è¼ƒå®Œæ¯å€‹ä¸»æˆåˆ†) Ansä»ç‚ºTrueï¼Œæˆ‘å€‘å°±èªªä»–å€‘æ˜¯ç›¸ç­‰çš„ (å¾ˆé è¿‘)ã€‚\n",
    "print(Ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 3\n",
    "The sequence $\\lambda_1,\\ldots,\\lambda_r$ are suppose to be the values in `explained_variance_` .  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('hidden_text.csv', delimiter=',')\n",
    "\n",
    "r = 2\n",
    "X = X - X.mean(axis=0) # Shift X so that the rows of X are centered at the origin.\n",
    "N,d = X.shape # X is an array of shape (N,d), and we need the number of N to calculate C.\n",
    "C = (X.T.dot(X))/N # C is a convariance matrix.\n",
    "vals,vecs = np.linalg.eigh(C) # Get the eigenvalues and eigenvectors of C.\n",
    "vals = vals[::-1] # Make eigenvalues from large to small.\n",
    "vecs = vecs[:,::-1] # Make eigenvectors from large to small.\n",
    "U = vecs[:,:r] # U only need the first r columns of vecs matrix.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(r)\n",
    "X_new = model.fit_transform(X)\n",
    "\n",
    "print(np.allclose(vals[:r],model.explained_variance_)) \n",
    "# Their errors are bigger than model.explained_variance_*rtol (rtol = 1.e-5), so we cannot say they are same under rtol = 1.e-5.\n",
    "print(model.explained_variance_) # Observe the value of model.explained_variance_.\n",
    "print(vals[:r]) # Observe the value of vals[:r].\n",
    "# I think this two arrays are very close, so I try to  adjust the rtol of np.allclose function.\n",
    "Ans = np.allclose(vals[:r],model.explained_variance_,rtol = 1.e-3)\n",
    "print(Ans)\n",
    "# Hence, under the rtol = 1.e-3, we can say they are same (very close)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 4\n",
    "Let $t = \\operatorname{tr}(C)$.  \n",
    "The sequence $\\lambda_1/t,\\ldots,\\lambda_r/t$ are suppose to be the values in `explained_variance_ratio_` .  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('hidden_text.csv', delimiter=',')\n",
    "\n",
    "r = 2\n",
    "X = X - X.mean(axis=0) # Shift X so that the rows of X are centered at the origin.\n",
    "N,d = X.shape # X is an array of shape (N,d), and we need the number of N to calculate C.\n",
    "C = (X.T.dot(X))/N # C is a convariance matrix.\n",
    "vals,vecs = np.linalg.eigh(C) # Get the eigenvalues and eigenvectors of C.\n",
    "vals = vals[::-1] # Make eigenvalues from large to small.\n",
    "vecs = vecs[:,::-1] # Make eigenvectors from large to small.\n",
    "U = vecs[:,:r] # U only need the first r columns of vecs matrix.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(r)\n",
    "X_new = model.fit_transform(X)\n",
    "\n",
    "t = np.trace(C)\n",
    "Ans = np.allclose(vals[:r]/t,model.explained_variance_ratio_) \n",
    "# If the sequence ğœ†1/ğ‘¡,â€¦,ğœ†ğ‘Ÿ/ğ‘¡ and explained_variance_ratio_ are same (very close), Ans will equal True.\n",
    "print(Ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5\n",
    "The singular values of the shifted `X` are supposed to be `model.singular_values_` .  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('hidden_text.csv', delimiter=',')\n",
    "\n",
    "r = 2\n",
    "X = X - X.mean(axis=0) # Shift X so that the rows of X are centered at the origin.\n",
    "N,d = X.shape # X is an array of shape (N,d), and we need the number of N to calculate C.\n",
    "C = (X.T.dot(X))/N # C is a convariance matrix.\n",
    "vals,vecs = np.linalg.eigh(C) # Get the eigenvalues and eigenvectors of C.\n",
    "vals = vals[::-1] # Make eigenvalues from large to small.\n",
    "vecs = vecs[:,::-1] # Make eigenvectors from large to small.\n",
    "U = vecs[:,:r] # U only need the first r columns of vecs matrix.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(r)\n",
    "X_new = model.fit_transform(X)\n",
    "\n",
    "u,s,v = np.linalg.svd(X) # s is an array of singular values (from large to small).\n",
    "Ans = np.allclose(s[:r],model.singular_values_) \n",
    "# If first r of singular values of the shifted X and model.singular_values_ are same (very close), Ans will equal True.\n",
    "print(Ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
