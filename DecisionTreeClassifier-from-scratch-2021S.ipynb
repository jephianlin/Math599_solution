{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "**Input:**  \n",
    "- `X`: an array of shape `(N,d)` whose rows are samples and columns are features\n",
    "- `y`: the labels of shape `(N,)`\n",
    "- `criterion`: `\"gini\"` or `\"entropy\"`  \n",
    "\n",
    "**Output:**  \n",
    "A tuple `(predict, tree)`.  \n",
    "- `predict`: a function that takes data `X_sample` and output their predicted labels\n",
    "- `tree`: a dictionary that contains the information same as those in `model.tree_`\n",
    "\n",
    "**Steps:**\n",
    "1. Define $\\operatorname{node}({\\bf x}) = 0$ for every sample point ${\\bf x}$.  \n",
    "2. Let `queue = [0]` and `node_count = 0` .\n",
    "3. While `queue` is not empty:  \n",
    "    1. Pick the first element $k$ from `queue` and remove it.\n",
    "    2. Let $U$ be the points with $\\operatorname{node}({\\bf x}) = k$.\n",
    "    3. Compute $\\operatorname{imp}(k)$ as the impurity of labels of $U$.  \n",
    "If $\\operatorname{imp}(k)=0$, then skip this loop.\n",
    "    4. For each feature $f_j$ and each sample point ${\\bf x}_i\\in U$, partition $U$ into two parts $L$ and $R$ by the criteria $f_j({\\bf x}) \\leq f_j({\\bf x}_i)$, calculate the impurity $H_L$ and $H_R$ in each part, and obtain the value  \n",
    "$$I'_{j,i} = \\frac{|L|}{|U|}H_L + \\frac{|R|}{|U|}H_R,$$\n",
    "which is a nonpositive value.\n",
    "    5. Pick a pair $j$ and $i$ that achieves the minimum $I'_{j,i}$.  \n",
    "Let $\\operatorname{node}({\\bf x})$ be `node_count+1` if ${\\bf x}\\in L$.  \n",
    "Let $\\operatorname{node}({\\bf x})$ be `node_count+2` if ${\\bf x}\\in R$.  \n",
    "Let `queue += [node_count+1, node_count+2]` and `node_count += 2` .\n",
    "\n",
    "4. Each new point falls into a unique leaf in your decision tree.  Since each leaf contains only one class, use the class as the prediction of this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode\n",
    "Translate the algorithm into the pseudocode.  \n",
    "This helps you to identify the parts that you don't know how to do it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. \n",
    "    2. \n",
    "    3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "class MyDecisionTreeClassifier():\n",
    "    def __init__(self, criterion=\"gini\"):\n",
    "        self.criterion = criterion\n",
    "        self.tree_ = self.tree()\n",
    "        \n",
    "    class tree():#Â≠òÂèñtree\n",
    "        children_left = []\n",
    "        children_right = []\n",
    "        feature = []\n",
    "        threshold = []\n",
    "        n_node_samples = []\n",
    "        impurity = []\n",
    "        depth = []\n",
    "        \n",
    "        def clear(self):\n",
    "            self.children_left.clear()#Ê∏ÖÁ©∫tree\n",
    "            self.children_right.clear()\n",
    "            self.feature.clear()\n",
    "            self.threshold.clear()\n",
    "            self.n_node_samples.clear()\n",
    "            self.impurity.clear()\n",
    "            self.depth.clear()\n",
    "        #step1\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #1.\n",
    "        self.tree_.clear()\n",
    "        node = np.zeros(X.shape[0])\n",
    "        self.tree_.depth.append(1)\n",
    "        self.max_depth = 0\n",
    "        #2.Let queue = [0] and node_count = 0 .\n",
    "        queue = [0]\n",
    "        node_count = 0\n",
    "        #3.ÂàÜÁæ§\n",
    "        while len(queue) > 0: #While queue is not empty: QueueÊòØ‰ª£Ë°®ÊúâÂπæÁæ§\n",
    "            #A.\n",
    "            k = queue.pop(0)#ÁßªÈô§Á¨¨‰∏ÄÂÄãÊï∏\n",
    "            #B.Let  ùëà  be the points with  node(ùê±)=ùëò .UÂÑ≤Â≠òÂÄº\n",
    "            U = np.where(node == k)[0]\n",
    "            #C.     \n",
    "            if self.imp(y[U]) == 0:#ÂæàÁ¥îÁöÑË©±Â∞±‰∏çÁî®ÂàÜÁæ§\n",
    "                self.tree_.children_left.append(-1) #Êää-1‰∏üÈÄ≤Âéª\n",
    "                self.tree_.children_right.append(-1)\n",
    "                self.tree_.feature.append(-1)\n",
    "                self.tree_.threshold.append(-1)\n",
    "                self.tree_.n_node_samples.append(len(U))\n",
    "                self.tree_.impurity.append(0)\n",
    "                if self.tree_.depth[k] > self.max_depth:\n",
    "                    self.max_depth = self.tree_.depth[k]\n",
    "                continue\n",
    "            #D.Â∞ãÊâæÊúÄ‰Ω≥ÁöÑÂàÜÈ°ûÈªû\n",
    "            minI = np.inf#Ë®≠ÁÑ°Á∑öÂ§ß\n",
    "            minj = 0\n",
    "            mini = 0\n",
    "            #jÁâπÂæµÁõ¥/i:node\n",
    "            for j in range(X.shape[1]):\n",
    "                for i in range(len(U)):\n",
    "                    L = U[X[U, j]<=X[U[i], j]]  #f_j(ùê±)‚â§f_j(ùê±_i) //x(N,d)\n",
    "                    R = U[X[U, j]>X[U[i], j]]   #f_j(ùê±)>f_j(ùê±_i)\n",
    "                    H_L = self.imp(y[L]) #impurity_left\n",
    "                    H_R = self.imp(y[R])\n",
    "                    I = len(L)/len(U)*H_L + len(R)/len(U)*H_R\n",
    "                    if I < minI:\n",
    "                        minI = I\n",
    "                        minj = j\n",
    "                        mini = i\n",
    "            #E.ÂàÜÈ°û\n",
    "            self.tree_.children_left.append(node_count + 1)\n",
    "            self.tree_.children_right.append(node_count + 2)\n",
    "            self.tree_.feature.append(minj)\n",
    "            self.tree_.threshold.append(X[U[mini], minj])\n",
    "            self.tree_.n_node_samples.append(len(U))\n",
    "            self.tree_.impurity.append(minI)\n",
    "            \n",
    "            L = U[X[U, minj]<=X[U[mini], minj]]  #f_j(ùê±)‚â§f_j(ùê±_i)\n",
    "            R = U[X[U, minj]>X[U[mini], minj]]   #f_j(ùê±)>f_j(ùê±_i)\n",
    "            node[L] = node_count + 1\n",
    "            node[R] = node_count + 2\n",
    "            queue += [node_count+1, node_count+2]\n",
    "            self.tree_.depth.append(self.tree_.depth[k]+1)\n",
    "            self.tree_.depth.append(self.tree_.depth[k]+1)\n",
    "            node_count += 2\n",
    "            \n",
    "        #4.\n",
    "        node_class = []#list\n",
    "        mask = np.unique(node) #11223444/1234\n",
    "        for c in mask:\n",
    "            node_class.append([c, y[node == c][0]]) #Á¨¨ÂπæÁæ§ ÊúâÂπæÂÄã\n",
    "        self.node_class = np.array(node_class)\n",
    "            \n",
    "    def imp(self, y): \n",
    "        mask = np.unique(y)\n",
    "        imp = 0\n",
    "        if self.criterion == \"gini\":\n",
    "            for v in mask:\n",
    "                p = np.sum(y==v)/len(y)\n",
    "                imp += p*(1-p)\n",
    "        else:\n",
    "            for v in mask:\n",
    "                p = np.sum(y==v)/len(y)\n",
    "                imp -= p*np.log(p)\n",
    "        return imp\n",
    "    \n",
    "    def predict(self, X):#È†êÊ∏¨/Ë∑üÂâçÈù¢È°û‰ºº\n",
    "        #1.\n",
    "        node = np.zeros(X.shape[0])\n",
    "        #2.\n",
    "        queue = [0]\n",
    "        node_count = 0\n",
    "        #3.\n",
    "        while len(queue) > 0:\n",
    "            #A.\n",
    "            k = queue.pop(0)\n",
    "            #B.\n",
    "            U = np.where(node == k)[0]\n",
    "            #C.\n",
    "            if k in self.node_class[:, 0]:\n",
    "                continue\n",
    "            #D.\n",
    "            j = self.tree_.feature[k]\n",
    "            f = self.tree_.threshold[k]\n",
    "            #E.\n",
    "            L = U[X[U, j]<=f]\n",
    "            R = U[X[U, j]>f]\n",
    "            node[L] = node_count + 1\n",
    "            node[R] = node_count + 2\n",
    "            queue += [node_count+1, node_count+2]\n",
    "            node_count += 2\n",
    "            \n",
    "        #4.\n",
    "        y = node\n",
    "        mask = np.unique(node)\n",
    "        for c in mask:\n",
    "            y[node == c] = self.node_class[self.node_class[:, 0] == c][0, 1]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = np.zeros(5)\n",
    "node[3] = 1\n",
    "queue = [0]\n",
    "node_count = 0\n",
    "while len(queue) > 0:\n",
    "    k = queue.pop(0)\n",
    "    U = np.where(node == k)[0]\n",
    "queue += [2,3]\n",
    "queue = np.array([[1,2,3],[4,2,3],[5,2,3],[6,2,3]])\n",
    "np.where(queue[:,0]==5)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "I guess the cell above is only for testing and can be removed.\n",
    "\n",
    "The line `U = np.where(node == k)[0]` can be replaced by `U = (node == k)` .  \n",
    "The meaning is a bit differnt though.  \n",
    "The former returns an array of indices, while the later returns a boolean array.\n",
    "\n",
    "The `imp` funcion can be defined without `for` loops.  See example below.\n",
    "```python\n",
    "    def impurity(arr):\n",
    "        dtrib = np.unique(arr, return_counts=True)[1]\n",
    "        dtrib = dtrib / dtrib.sum()\n",
    "        if criteria == \"gini\":\n",
    "            return np.sum(dtrib * (1 - dtrib))\n",
    "        if criteria == \"entropy\":\n",
    "            return np.sum(-dtrib * np.log2(dtrib))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Take some sample data from [DecisionTreeClassifier-with-scikit-learn](DecisionTreeClassifier-with-scikit-learn.ipynb) and check if your code generates similar outputs with the existing packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Name of the data\n",
    "Description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### results with your code\n",
    "# X: an array of shape (N,d) whose rows are samples and columns are features\n",
    "# y: the labels of shape (N,)\n",
    "mu = np.array([1,1])\n",
    "cov = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "X = np.vstack([np.random.multivariate_normal(mu, cov, 100), \n",
    "               np.random.multivariate_normal(-mu, cov, 100)])\n",
    "y = np.array([0]*100 + [1]*100)\n",
    "\n",
    "X_sample = np.vstack([np.random.multivariate_normal(mu, cov, 100), \n",
    "               np.random.multivariate_normal(-mu, cov, 100)])\n",
    "y_sample = np.array([0]*100 + [1]*100)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)#Ë®ìÁ∑¥\n",
    "y_new1 = model.predict(X_sample)#È†êÊ∏¨\n",
    "#print(y_new)\n",
    "\n",
    "model = MyDecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "y_new2 = model.predict(X_sample)\n",
    "print('length of y')\n",
    "print(len(y_new1))\n",
    "print('sklearn accuracy:')\n",
    "print((np.sum(y_sample == y_new1)/len(y_new1)))#sklearn\n",
    "print('my accuracy:')\n",
    "print((np.sum(y_sample == y_new2)/len(y_new1)))#my\n",
    "print('how many the same:')\n",
    "print(np.sum(y_new1 == y_new2))\n",
    "\n",
    "\n",
    "\n",
    "print(model.tree_.n_node_samples)#nodeÂàÜÂà•ÊúâÂ§öÂ∞ëÂÄãÊï∏\n",
    "print(model.tree_.impurity)#Á¥îÂ∫¶0Â∞±‰∏çÂàÜÁæ§\n",
    "print(model.tree_.depth)#ÂàÜÂà•Â±¨ÊñºÂì™‰∏ÄÂ±§\n",
    "print(model.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### results with existing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Train a decision tree classification model by `X` and `y` .  \n",
    "Make a prediction of `X_sample` by:  \n",
    "1. your code with different algorithm settings\n",
    "2. `sklearn.neighbors.KNeighborsClassifier`\n",
    "\n",
    "The results should be the same (or almost the same).  \n",
    "Check if this is true.  \n",
    "(Note: the uncertainty is caused by the choice of cut when there are several cuts with the same information gain.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*20 + [1]*20)\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "y_new1 = model.predict(X_sample)\n",
    "\n",
    "model = MyDecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "y_new2 = model.predict(X_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "It seems the prediction is somewhat different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*20 + [1]*20)\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "y_new1 = model.predict(X_sample)\n",
    "\n",
    "mod = MyDecisionTreeClassifier()\n",
    "mod.fit(X, y)\n",
    "y_new2 = mod.predict(X_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Let `y_new` be the prediction of `X_sample` in the previous question. \n",
    "Plot the points (rows) in `X` with `c=y` .  \n",
    "Plot the points (rows) in `X_sample` with `c=y_new` and `alpha=0.1` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "plt.scatter(*X.T, c=y)\n",
    "plt.scatter(*X_sample.T, c=y_new1, alpha=0.1)#ÈÄèÊòéÂ∫¶\n",
    "#ÂàáÁöÑ4ÂÄãË∑ü‰∏ãÂúñÈªû‰∏çÂêå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X.T, c=y)\n",
    "plt.scatter(*X_sample.T, c=y_new2, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Looks like sklearn is cutting by $f_j({\\bf x}) \\leq (f_j({\\bf x}_i) + f_j({\\bf x}_{i+1})) / 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Let  \n",
    "```python\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "```  \n",
    "The corresponding values in `model.tree_` and those in your `tree` should be almost the same.  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "#Â∑¶Âè≥ÂÆöÁæ©‰∏çÂêådefiniti\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "print(model.tree_.n_node_samples)\n",
    "model = MyDecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "print(model.tree_.n_node_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2)\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n))\n",
    "xx = np.zeros((frames, m, n))\n",
    "count =  0\n",
    "for i in range(m-2):\n",
    "    for j in range(n-2):\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2)\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n))\n",
    "xx = np.zeros((frames, m, n))\n",
    "count =  0\n",
    "for i in range(m-2):\n",
    "    for j in range(n-2):\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Train a decision tree classification model by `X` an `y` .  \n",
    "Make a prediction `y_new` for the training data `X` .  \n",
    "What is the outcome?  \n",
    "Can we say decision tree model is better than the $k$-nearest neighbors model?  (open answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "model = MyDecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "y_new = model.predict(X)\n",
    "print(y_new)\n",
    "print(y)\n",
    "#knn:  high accuracy but complicated calculation\n",
    "#decisiomtree:easy to undestand but information gain toward to  features,overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "Print the `n_node_samples` for each leaf.  \n",
    "Does the leaves contain many samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "print(model.tree_.n_node_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "The question is asking leaf nodes, so do the following.\n",
    "```python\n",
    "T = model.tree_\n",
    "Tleft = T.children_left\n",
    "[T.n_node_samples[i] for i in range(len(Tleft)) if Tleft[i] == -1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(c)\n",
    "What is the depth of the decision tree?  \n",
    "(The depth of a tree is the number of vertices on the longest path from a root to a leaf.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "print(model.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
