{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "**Input:**  \n",
    "- `X`: an array of shape `(N,d)` whose rows are samples and columns are features\n",
    "- `y`: the labels of shape `(N,)`\n",
    "- `k`: Numbers of neighbors (including self) to vote\n",
    "- `algorithm`: `'brute'`, `'ball_tree'`, or `'kd_tree'`\n",
    "\n",
    "**Output:**  \n",
    "A tuple `(predict, k_nearest_neighbors)`.  \n",
    "- `predict`: a function that takes data `X_sample` and output their predicted labels\n",
    "- `k_nearest_neighbors`: a function that takes data `X_sample` and return an array of shape `(X_sample_height, k)` that stores the indices of the nearest neighbors in `X` for each row in `X_sample`\n",
    "\n",
    "**Steps:**\n",
    "1. If `algorithm==\"brute\"`, create the function `k_nearest_neighbors` by the distance matrix.  \n",
    "2. If `algorithm==\"ball_tree\"` or `algorithm==\"kd_tree\"`, create the function `k_nearest_neighbors` by `sklearn.neighbors.NearestNeighbors` with the corresponding algorithm.\n",
    "3. Create the function `predict` that executes the following steps:\n",
    "    1. Input `X_sample` .\n",
    "    2. Let `nbrhoods = k_nearest_neighbors(X_sample)` .  \n",
    "    3. Let `votes = y[nbrhoods]` .\n",
    "    4. Calculate the most frequent label in each row of `votes` and store the results in `y_new` .\n",
    "    5. Return `y_new` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode\n",
    "Translate the algorithm into the pseudocode.  \n",
    "This helps you to identify the parts that you don't know how to do it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Create function knn with inputs: X, y, algorithm, and k\n",
    "    2. sub-function k_nearest_neighbors return k nearest neighbors of sample X \n",
    "    3. sub-function predict return labels of k nearest neighbors\n",
    "    4. If algorithm==\"brute\", creating the funciton k_nearest_neighbors by the distance matrix (dist_mtx(X, Y)).\n",
    "    5. If algorithm==\"ball_tree\" or algorithm==\"kd_tree\", create the function k_nearest_neighbors by sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "\n",
    "def dist_mtx(X, Y):\n",
    "    X_col = X[:,np.newaxis,:]\n",
    "    Y_row = Y[np.newaxis,:,:]\n",
    "    diff = X_col - Y_row\n",
    "    dist = np.linalg.norm(diff, axis=-1)\n",
    "    return dist\n",
    "\n",
    "def get_y(kneighbors, y):\n",
    "    # y[kneighbors] => pick the class value by the index of kneighbors\n",
    "    # use scipy.stats.mode to find out mode in y, and reshape to vectors\n",
    "    return stats.mode(y[kneighbors], axis=1).mode.reshape(kneighbors.shape[0])\n",
    "\n",
    "def knn(X, y, algorithm, k):\n",
    "    # find out the indeices of k-neighbors\n",
    "    if algorithm == 'brute':\n",
    "        def k_nearest_neighbors(X_sample):\n",
    "            dist = dist_mtx(X_sample, X)\n",
    "            argp = dist.argpartition(k-1, axis=1)\n",
    "            return argp[:,:k]\n",
    "        def predict(X_sample):\n",
    "            k_neighbors = k_nearest_neighbors(X_sample)\n",
    "            return get_y(k_neighbors, y)\n",
    "            \n",
    "    elif algorithm in ['ball_tree', 'kd_tree']:\n",
    "        def k_nearest_neighbors(X_sample):\n",
    "            nbr = NearestNeighbors(n_neighbors=k, algorithm=algorithm)\n",
    "            nbr.fit(X)\n",
    "            return nbr.kneighbors(X_sample, return_distance=False)\n",
    "        def predict(X_sample):\n",
    "            k_neighbors = k_nearest_neighbors(X_sample)\n",
    "            return get_y(k_neighbors, y)\n",
    "    return predict, k_nearest_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Nice.  \n",
    "It seems that the definition of `predict` is the same in each case, so maybe you may define it outside of the `if` statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Take some sample data from [KNeighborsClassifier-with-scikit-learn](KNeighborsClassifier-with-scikit-learn.ipynb) and check if your code generates similar outputs with the existing packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Name of the data\n",
    "Description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### results with your code\n",
    "mu1 = np.array([2.5,0])\n",
    "cov1 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "mu2 = np.array([-2.5,0])\n",
    "cov2 = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "y = np.array([0]*100 + [1]*100)\n",
    "X_sample = np.random.uniform(low=-5, high=5, size=(1000,2))\n",
    "plt.scatter(*X.T, c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict, k_nearest_neighbors  = knn(X, y, 'brute', 2)\n",
    "y_new = predict(X_sample)\n",
    "plt.figure(figsize=(6, 6)) \n",
    "plt.subplot(311).set_title('brute')\n",
    "plt.scatter(*X_sample.T, c=y_new)\n",
    "\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'ball_tree', 2)\n",
    "y_new = predict(X_sample)\n",
    "plt.subplot(312).set_title('ball_tree')\n",
    "plt.scatter(*X_sample.T, c=y_new)\n",
    "\n",
    "predict, k_nearest_neighbors  = knn(X, y, 'kd_tree', 2)\n",
    "y_new = predict(X_sample)\n",
    "plt.subplot(313).set_title('kd_tree')\n",
    "plt.scatter(*X_sample.T, c=y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### results with existing packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X, y)\n",
    "y_new = model.predict(X_sample)\n",
    "plt.figure(figsize=(6, 2))\n",
    "plt.suptitle('sklearn')\n",
    "plt.scatter(*X_sample.T, c=y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*20 + [1]*20)\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Train a $k$-nearest neighbors classification model by `X` and `y` .  \n",
    "Make a prediction of `X_sample` by:  \n",
    "1. your code with different algorithm settings\n",
    "2. `sklearn.neighbors.KNeighborsClassifier`\n",
    "\n",
    "The results should be the same.  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*20 + [1]*20)\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "\n",
    "predict, k_nearest_neighbors = knn(X, y, 'brute', 2)\n",
    "kneighbors_scratch_brute = k_nearest_neighbors(X_sample)\n",
    "y_new_scratch_brute = predict(X_sample)\n",
    "\n",
    "predict, k_nearest_neighbors = knn(X, y, 'ball_tree', 2)\n",
    "kneighbors_scratch_ball_tree = k_nearest_neighbors(X_sample)\n",
    "y_new_scratch_ball_tree = predict(X_sample)\n",
    "\n",
    "predict, k_nearest_neighbors = knn(X, y, 'kd_tree', 2)\n",
    "kneighbors_scratch_kd_tree = k_nearest_neighbors(X_sample)\n",
    "y_new_scratch_kd_tree = predict(X_sample)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X, y)\n",
    "y_new_scikit = model.predict(X_sample)\n",
    "\n",
    "print(((y_new_scratch_brute==y_new_scratch_ball_tree) & \n",
    "       (y_new_scratch_ball_tree==y_new_scratch_kd_tree) & \n",
    "       (y_new_scratch_kd_tree==y_new_scikit)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Let `y_new` be the prediction of `X_sample` in the previous question. \n",
    "Plot the points (rows) in `X` with `c=y` .  \n",
    "Plot the points (rows) in `X_sample` with `c=y_new` and `alpha=0.1` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "plt.scatter(*X.T, c=y, label=\"Training data\", marker=\"^\", s=60)\n",
    "plt.scatter(*X_sample.T, c=y_new_scratch_brute, alpha=0.1, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Let  \n",
    "```python\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "```  \n",
    "and let `k_nearest_neighbors` be one of the output of your function.  \n",
    "The results of `k_nearest_neighbors(X_sample)` should be the same as `model.kneighbors(X_sample, return_distance=False)` .  \n",
    "(The corresponding rows contains the same collection of elements, but might be in different order.)  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "predict, k_nearest_neighbors = knn(X, y, 'brute', 2)\n",
    "neighbors = k_nearest_neighbors(X_sample)\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X, y)\n",
    "print((neighbors==model.kneighbors(X_sample, return_distance=False)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2)\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n))\n",
    "xx = np.zeros((frames, m, n))\n",
    "count =  0\n",
    "for i in range(m-2):\n",
    "    for j in range(n-2):\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Run  \n",
    "```python\n",
    "plt.imshow(oo[i], cmap=\"Greys\")\n",
    "```\n",
    "with different `i` .  \n",
    "Guess what is the meaning of `oo` and `xx` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2)\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n))\n",
    "xx = np.zeros((frames, m, n))\n",
    "count =  0\n",
    "for i in range(m-2):\n",
    "    for j in range(n-2):\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        ax = plt.subplot2grid((6,6), (i,j))\n",
    "        ax.imshow(oo[i*6+j], cmap=\"Greys\")\n",
    "print('oo is a 36 images set, an o-like object in each image from left to right, up to down with step 1')\n",
    "print('xx is a 36 images set, an x-like object in each image from left to right, up to down with step 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "Train a $k$-nearest neighbors classification model by `X` an `y` .  \n",
    "Make a prediction `y_new` for the training data `X` .  \n",
    "What is the outcome?  \n",
    "Can you give a reason to this phenomenon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "for k in range(1,10):\n",
    "    predict, k_nearest_neighbors = knn(X, y, 'brute', k)\n",
    "    y_new = predict(X)\n",
    "    print(y_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reason\n",
    "```\n",
    "when test data is o[0], then\n",
    "   || o[0]  - o[0] || = 0 \n",
    "   || o[0]  - o[1] || = 5  \n",
    "   || o[0]  - o[2] || = 10 \n",
    "   || o[0]  - o[3~5] || = 9 \n",
    "   || o[0]  - o[6] || = ...\n",
    "   || o[0]  - x[0] || = 5  \n",
    "   || o[0]  - x[1] || = 7  \n",
    "   || o[0]  - x[2] || = 9  \n",
    "   || o[0]  - x[3~5] || = 13\n",
    "   and so on ...\n",
    "\n",
    "else if test data is x[0], then\n",
    "   || x[0]  - o[0] || = 5 \n",
    "   and so on ...\n",
    "\n",
    "Thus, \n",
    "when k=1, the one itself will be the only answer in all 72 images, accuracy = 100%\n",
    "when k=2, ...\n",
    "and so on ...\n",
    "\n",
    "Different k will got different nearest neighbors (lowest norm between) from o and x, and result in different inference\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Indeed, so the brief answer is that the neighbors of a point in `oo` are mostly points in `xx` but not points in `oo` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Well done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
