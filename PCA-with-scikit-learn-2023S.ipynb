{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(<parameters>)\n",
    "X_new = model.fit_transform(X)\n",
    "```\n",
    "\n",
    "[Official Reference](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- `n_components`: target dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "- `n_samples`: height of `X`\n",
    "- `n_features`: width of `X`\n",
    "- `n_components_`: target dimension\n",
    "- `components_`: `n_components` rows of principal components\n",
    "- `mean_`: `X.mean(axis=0)`\n",
    "- `explained_variance_`: importance of each component\n",
    "- `explained_variance_ratio_`: importance of each component in ratio\n",
    "- `singular_values_`: singular values of shifted `X`  \n",
    "(`singular_values_**2 / n_samples_ == explained_variance_`)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "mu = np.array([3,4])\n",
    "cov = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.random.multivariate_normal(mu, cov, 100)\n",
    "```\n",
    "Let `X_new` be the result of PCA on `X` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "mu = np.array([3,4])\n",
    "cov = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.random.multivariate_normal(mu, cov, 100)\n",
    "\n",
    "model = PCA()\n",
    "X_new = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Plot points (rows) in `X` .  \n",
    "Plot points (rows) in `X_new` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], X[:,1]) # blue\n",
    "ax.scatter(X_new[:,0], X_new[:,1]) # orange\n",
    "plt.legend(['X','X_new'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1(b)\n",
    "Adding on top of the previous figure, draw vectors for the rows in `model.components_` with the tails at `model.mean_` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], X[:,1]) # blue\n",
    "ax.scatter(X_new[:,0], X_new[:,1]) # orange\n",
    "ax.arrow(* model.mean_,*model.components_[0],color='red',head_width=0.2)\n",
    "ax.arrow(*model.mean_,*model.components_[1],color='red',head_width=0.2)\n",
    "plt.axis('equal')\n",
    "plt.legend(['X','X_new'])\n",
    "## two principal components are orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Print `model.explained_variance_ratio_` .  \n",
    "How important is the first component in percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.explained_variance_ratio_\n",
    "print(model.explained_variance_ratio_[0])\n",
    "#The model can explain around 96% of the variance in the dataset.\n",
    "#The larger the variance explained by a principal component, the more important that component is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "around 96%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "X = np.genfromtxt('hidden_text.csv', delimiter=',')\n",
    "```\n",
    "This data has all its points lie in a two-dimensional plane embedded in a much higher dimension.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('hidden_text.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Can you find out what does this data say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "# it cannot see any info\n",
    "# So we need to use other aspect to see it.\n",
    "# problem -> in high-dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0],X[:, 1])\n",
    "# we can see that there is a text?\n",
    "# it need to rotate ?\n",
    "# and we think that using 2-dim can catch the most outline in data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA(n_components=2)\n",
    "X_new = model.fit_transform(X)\n",
    "plt.scatter(X_new[:, 0],X_new[:, 1])\n",
    "plt.axis('equal')\n",
    "# when we do dimensionality reduction to 2-dim we can see the info, which graph shows NSYSU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "How much does the first two components have explained in ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.explained_variance_ratio_)\n",
    "# and using 2-dim ,it can explain ablut 99.9% info in this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 3\n",
    "Let  \n",
    "```python\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(a)\n",
    "Let `X_new` be the result of applying PCA to `X` with 30 components.  \n",
    "Use the first two columns as the $x$,$y$-coordinates and plot the points with `c=y` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "model = PCA(n_components=30)\n",
    "X_new = model.fit_transform(X)\n",
    "plt.scatter(X_new[:,0],X_new[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(b)\n",
    "Use the first three columns as the $x$,$y$,$z$-coordinates and plot the points with `c=y` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### your answer here\n",
    "from mpl_toolkits import mplot3d\n",
    "plt.axes(projection = '3d')\n",
    "plt.scatter(X_new[:,0],X_new[:,1],X_new[:,2], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(c)\n",
    "Use `plt.plot` to plot `model.explained_variance_` .  \n",
    "What is an appropriate choice of the target dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "plt.plot(model.explained_variance_)\n",
    "#10 is appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 4\n",
    "Let  \n",
    "```python\n",
    "mu = np.array([3,4])\n",
    "cov = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.random.multivariate_normal(mu, cov, 100)\n",
    "\n",
    "model = PCA(2)\n",
    "X_new = model.fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([3,4])\n",
    "cov = np.array([[1.1,1],\n",
    "                [1,1.1]])\n",
    "X = np.random.multivariate_normal(mu, cov, 100)\n",
    "\n",
    "model = PCA(2)\n",
    "X_new = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(a)\n",
    "Let  \n",
    "```python\n",
    "X_shifted = X - model.mean_\n",
    "```\n",
    "Plot the points (rows) of `X` .  \n",
    "Plot the points (rows) of `X_shifted` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shifted = X - model.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], X[:,1]) # blue\n",
    "ax.scatter(X_shifted[:,0], X_shifted[:,1]) # orange\n",
    "plt.legend(['X', 'X_shifted'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(b)\n",
    "Check the rows of `model.components_` are mutually orthogonal and of length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In linear algbra, we know that if components are mutually orthogonal, \n",
    "# which means that its inner product is 0.\n",
    "print(model.components_[0].dot(model.components_[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len = np.linalg.norm(model.components_, axis = 1)\n",
    "print(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(c)\n",
    "Let  \n",
    "```python\n",
    "X_proj = X_shifted.dot(model.components_.T)\n",
    "```\n",
    "Plot the points (rows) of `X_shifted` .\n",
    "Plot the points (rows) of `X_proj` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = X_shifted.dot(model.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_shifted[:,0], X_shifted[:,1]) # blue\n",
    "ax.scatter(X_proj[:,0], X_proj[:,1]) # orange\n",
    "plt.legend(['X_shifted','X_proj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(d)\n",
    "Suppose `model.mean_` and `model.components_` are given.  \n",
    "Can you find a way to obtained `X` from `X_new` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the inverse transformation of X_new to obtain X\n",
    "X_recover = np.dot(X_new, model.components_) + model.mean_\n",
    "model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_shifted[:,0], X_shifted[:,1]) # blue\n",
    "ax.scatter(X_recover[:,0], X_recover[:,1]) # orange\n",
    "plt.legend(['X_shifted','X_recover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inverse_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veronica  \n",
    "\n",
    "It will be better to plot the graph from the following codes to check whether the original `X` and `X_recover` are close or not.\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "plt.scatter(*X_recover.T,color='blue',s=50)\n",
    "plt.scatter(*X.T,color='red',s=10)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
