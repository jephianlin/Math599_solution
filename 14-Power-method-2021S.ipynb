{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A$ be a symmetric matrix with eigenvalues $\\lambda_0\\leq\\cdots\\leq\\lambda_{n-1}$ such that $\\lambda_{n-1}$ has the largest magnitude comparing to other distinct eigenvalues.  \n",
    "Then the following algorithm will approximate an eigenvector of $A$ with respect to $\\lambda_{n-1}$.\n",
    "1. Start with a random vector ${\\bf x}_0$ in $\\mathbb{R}^n$.\n",
    "2. Let ${\\bf x}_{k+1} = \\frac{A{\\bf x}_k}{\\|A{\\bf x}_k\\|}$.  \n",
    "\n",
    "When $k$ is large, ${\\bf x}_k$ is close to an eigenvector of $A$ with respect to $\\lambda_{n-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- finding all eigenvalues\n",
    "- PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[0,1,0,0,1],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [1,0,0,1,0]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Pick a random vector ${\\bf x}_0$ in $\\mathbb{R}^5$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "np.random.seed(1)\n",
    "x = np.random.randn(5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Apply the power method:\n",
    "- Let ${\\bf x}_{k+1} = \\frac{A{\\bf x}_k}{\\|A{\\bf x}_k\\|}$. \n",
    "\n",
    "Find ${\\bf x}_{1000}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.array([[0,1,0,0,1],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [1,0,0,1,0]])\n",
    "\n",
    "for i in range(1000):\n",
    "    x = A.dot(x) / np.sqrt((A.dot(x)).dot(A.dot(x)))\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "You may store `A.dot(x)` in some variable  \n",
    "so that you do not have to compute it several times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Check if your ${\\bf x}_{1000}$ looks like an eigenvector or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "print(A.dot(x) / x) # Check eigenvalue\n",
    "print('Yes, it is!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[0,0,1,1,1],\n",
    "              [0,0,1,1,1],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Use the power method to find ${\\bf x}_{1000}$ and check if it is an eigenvector.  \n",
    "If no, what might go wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.array([[0,0,1,1,1],\n",
    "              [0,0,1,1,1],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "x = np.random.randn(5)\n",
    "\n",
    "for i in range(1000):\n",
    "    x = A.dot(x) / np.sqrt((A.dot(x)).dot(A.dot(x)))\n",
    "    \n",
    "print(\"x1000: \", x)\n",
    "print(\"A * x1000: \", A.dot(x))\n",
    "print(\"A * x1000 / x1000: \", A.dot(x)/x) # Check eigenvalue\n",
    "print(\"No, it isn't.\")\n",
    "eigVal, eigVec = LA.eigh(A)\n",
    "print('The eigenvalues are',eigVal)\n",
    "print('Because there are the same absolute value of eigenvalue.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "Let  \n",
    "```python\n",
    "s = 10\n",
    "As = A + s*np.eye(5)\n",
    "```\n",
    "and apply the power method on $A_s$ to find ${\\bf x}_{1000}$.  \n",
    "Is it an eigenvector of $A_s$?  \n",
    "Is it an eigenvector of $A$?  \n",
    "What is the relation between the two eigenvalues?  \n",
    "\n",
    "(This workaround works whenever $s$ is large enough.  \n",
    "But how large?  \n",
    "In general, you may pick `s = np.abs(A).sum() + 1` .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "s = 10\n",
    "As = A + s*np.eye(5)\n",
    "\n",
    "x = np.random.randn(5)\n",
    "\n",
    "for i in range(1000):\n",
    "    x = As.dot(x) / np.sqrt((As.dot(x)).dot(As.dot(x)))\n",
    "\n",
    "print(\"x1000: \", x)\n",
    "print(\"As * x1000 / x1000: \", As.dot(x)/x)\n",
    "print(\"A * x1000 / x1000: \", A.dot(x)/x)\n",
    "print('Yes, both of them are!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 3\n",
    "Write a function  \n",
    "```python\n",
    "def power_method(A, iter=1000):\n",
    "    do something\n",
    "```\n",
    "that generate the largest eigenvalue of a symmetric matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "np.set_printoptions(precision = 2, suppress = True)\n",
    "\n",
    "def power_method(A, iter=1000):\n",
    "    s = np.abs(A).sum() + 1\n",
    "    A = A + s*np.eye(A.shape[0])\n",
    "    x = np.random.randn(A.shape[0])\n",
    "    for i in range(iter):\n",
    "        Ax = A.dot(x)\n",
    "        x = Ax / np.sqrt(Ax.dot(Ax)) # ||<Ax, Ax>||\n",
    "    return (A.dot(x) / x)[0] - s\n",
    "\n",
    "\n",
    "\n",
    "A = np.array([[0,0,1,1,1],\n",
    "              [0,0,1,1,1],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0]])\n",
    "\n",
    "print(power_method(A))\n",
    "eigVal, eigVec = LA.eigh(A)\n",
    "print('The true largest eigenvalue', max(eigVal))\n",
    "print('They are the same!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Since `x[0]` might be zero,  \n",
    "you may replace `(A.dot(x) / x)[0]` with `x.dot(A).dot(x)` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 4\n",
    "After you have found the largest few eigenvalues and their eigenvectors, you may apply the the enhanced version of the power method:\n",
    "1. Let $U$ be a matrix whose columns are the eigenvectors of length 1 for the largest few eigenvalues.\n",
    "2. Let $P = I -UU^\\top$ be the projection matrix onto the space orthogonal to $\\operatorname{Col}(U)$.\n",
    "2. Choose $s$ large enough and let $A_s = A+sI$.\n",
    "3. Pick a random vector ${\\bf x}_0$ and set ${\\bf x}\\leftarrow P{\\bf x}_0$.\n",
    "4. Let ${\\bf x}_{k+1} = \\frac{PA{\\bf x}_k}{\\|PA{\\bf x}_k\\|}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(a)\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[0,1,0,0,1],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [1,0,0,1,0]])\n",
    "```\n",
    "Find all eigenvalues and eigenvectors of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.array([[0,1,0,0,1],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [1,0,0,1,0]])\n",
    "\n",
    "vals, vecs = LA.eigh(A)\n",
    "print(\"eigenvalues: \\n\", vals)\n",
    "print(\"eigenvectors: \\n\", vecs)\n",
    "\n",
    "# power_method(A, U = np.delete(vecs, np.argmin(np.abs(vals)), axis = 1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(b)\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[0,0,1,1,1],\n",
    "              [0,0,1,1,1],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0]])\n",
    "```\n",
    "Find all eigenvalues and eigenvectors of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.array([[0,0,1,1,1],\n",
    "              [0,0,1,1,1],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0]])\n",
    "\n",
    "vals, vecs = LA.eigh(A)\n",
    "print(\"eigenvalues: \\n\", vals)\n",
    "print(\"eigenvectors: \\n\", vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(c)\n",
    "Upgrade your previous function\n",
    "```python\n",
    "def power_method(A, iter=1000, U=None):\n",
    "    do something\n",
    "```\n",
    "to implement this enhanced power method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "def power_method(A, iter=1000, U=None):          \n",
    "    dim = A.shape[0]\n",
    "    \n",
    "    if(type(U) == type(None)):\n",
    "        P = np.eye(dim)\n",
    "    else:\n",
    "        P = np.eye(dim) - U.dot(U.T)\n",
    "    s = np.abs(A).sum() + 1\n",
    "    As = A + s*np.eye(dim)\n",
    "    \n",
    "    x = np.random.randn(dim)\n",
    "    for i in range(iter):\n",
    "        x = P.dot(x)\n",
    "        x = P.dot(As.dot(x)) / np.linalg.norm(P.dot(As.dot(x)))\n",
    "    \n",
    "    eigVec = x\n",
    "    eigVal = (A.dot(x) / x)[0] # (As.dot(x) / x)[0] - s\n",
    "    \n",
    "    return eigVal, eigVec\n",
    "\n",
    "A = np.array([[0,0,1,1,1],\n",
    "              [0,0,1,1,1],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0]])\n",
    "vals, vecs = LA.eigh(A)\n",
    "print(\"eigenvalues: \\n\", vals)\n",
    "print(\"eigenvectors: \\n\", vecs)\n",
    "\n",
    "U = vecs[:, 4].reshape(5, 1)\n",
    "# U = vecs[:, 0:4]\n",
    "print('U =', U)\n",
    "vals_P, vecs_P = power_method(A, U = U)\n",
    "print(\"\\n\\npower_method: \\neigenvalues: \\n\", vals_P)\n",
    "print(\"eigenvectors: \\n\", vecs_P)\n",
    "print('\\n\\npower_method verification: \\neigenvectors: \\n', vecs_P.T, '\\nA %*% eigenvectors: \\n', A.dot(vecs_P.T), '\\neigenvalues: \\n', A.dot(vecs_P.T)/vecs_P.T)\n",
    "print('They are the same as the LA.eigh(A)!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Well done!  \n",
    "Here are some comments:  \n",
    "1. There is no point doing `(type(U) == type(None))`.  \n",
    "It is enough to say `U == None` .\n",
    "2. The output of `vecs[:, 4].reshape(5, 1)` and `vecs[:, [4]]` are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5\n",
    "Write a function  \n",
    "```python\n",
    "def my_eigh(A):\n",
    "    do something\n",
    "```\n",
    "that takes a symmetric matrix and returns its eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### your answer here\n",
    "def my_eigh(A):\n",
    "    dim = A.shape[0]\n",
    "    eigVec = np.zeros((dim, dim))\n",
    "    eigVal = np.zeros(dim)\n",
    "    U = None\n",
    "    \n",
    "    for k in range(dim):\n",
    "        Val, Vec = power_method(A, U = U)\n",
    "        eigVec[k, :] = Vec\n",
    "        U = eigVec[0:k+1, :].T\n",
    "        eigVal[k] = Val\n",
    "        \n",
    "    return eigVal, eigVec\n",
    "\n",
    "vals_P, vecs_P = my_eigh(A)\n",
    "print(\"\\n\\npower_method: \\neigenvalues: \\n\", vals_P)\n",
    "print(\"eigenvectors: \\n\", vecs_P)\n",
    "print('\\n\\npower_method verification: \\neigenvectors: \\n', vecs_P.T, '\\nA %*% eigenvectors: \\n', A.dot(vecs_P.T), '\\neigenvalues: \\n', A.dot(vecs_P.T)/vecs_P.T)\n",
    "print('They are the same as the LA.eigh(A)!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Beautiful!  The `my_eigh` can also take the keyword `iter` and pass it to `power_method` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6\n",
    "Let   \n",
    "```python\n",
    "A = np.array([[0,1,0,0,1],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [1,0,0,1,0]])\n",
    "vals,vecs = LA.eigh(A)\n",
    "Q = vecs\n",
    "```\n",
    "Let ${\\bf x}_0,\\ldots,{\\bf x}_{10}$ be the vectors generated by the power method.  \n",
    "Print the following for $k = 0,\\ldots, 9$.  \n",
    "1. $Q^\\top {\\bf x}_k$\n",
    "2. $Q^\\top A{\\bf x}_k$  \n",
    "3. The entrywise ratio of the vector in 2 over the vector in 1.\n",
    "4. `vals`\n",
    "5. `\"-----\" to separate different $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here\n",
    "A = np.array([[0,1,0,0,1],\n",
    "              [1,0,1,0,0],\n",
    "              [0,1,0,1,0],\n",
    "              [0,0,1,0,1],\n",
    "              [1,0,0,1,0]])\n",
    "vals,vecs = LA.eigh(A)\n",
    "Q = vecs\n",
    "print('Q =\\n', Q, '\\n')\n",
    "\n",
    "x0 = np.random.randn(5)\n",
    "x = []\n",
    "x.append(x0)\n",
    "for i in range(10):\n",
    "    x0 = A.dot(x0) / np.sqrt((As.dot(x0)).dot(As.dot(x0)))\n",
    "    x.append(x0)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"k = \", i)\n",
    "    print(Q.T.dot(x[i]))\n",
    "    print(Q.T.dot(A.dot(x[i])))\n",
    "    print(Q.T.dot(A.dot(x[i])) / Q.T.dot(x[i]))\n",
    "    print(vals)\n",
    "    if(i != 9):\n",
    "        print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jephian:\n",
    "Nice.  So you will see the line for $Q^\\top {\\bf x}_k$ is converging to $(0,0,0,0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 7\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[1,1,1,1,1],\n",
    "              [1,1,1,1,1],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0]])\n",
    "M = A / A.sum(axis=0)\n",
    "```\n",
    "Here $M$ is called a **transition matrix** since all of its entries are nonnegative and the each column sum is one.  \n",
    "There are five nodes $0,\\ldots, 4$.  \n",
    "A vector ${\\bf x}_0 = (x_0, x_1, x_2, x_3, x_4)^\\top$ with $x_i\\geq 0$ and $\\sum_{i}x_i = 1$ can be viewed as a **state** that describes the probability of a person staying at each node.  \n",
    "\n",
    "The transition matrix $M = \\begin{bmatrix}m_{ij}\\end{bmatrix}$ describes the probability of a person starts from $j$ and walk to $i$ in the next step.  \n",
    "Therefore, ${\\bf x}_{k+1} = M{\\bf x}_k$ is the state of the next step.  \n",
    "\n",
    "Find ${\\bf x}_{1000}$.  \n",
    "(Note that you don't have to normalized the length now since the sum is always equal to one.)  \n",
    "\n",
    "You will find out $M{\\bf x}_{1000}$ is very close to ${\\bf x}_{1000}$.  \n",
    "We call such probability state a **stationary state** of this Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer\n",
    "A = np.array([[1,1,1,1,1],\n",
    "              [1,1,1,1,1],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0],\n",
    "              [1,1,0,0,0]])\n",
    "M = A / A.sum(axis=0)\n",
    "\n",
    "x0 = np.array([1/3,1/3,1/6,1/12,1/12])\n",
    "\n",
    "for i in range(1000):\n",
    "    x0 = M.dot(x0)\n",
    "    \n",
    "print(\"x1000: \", x0)\n",
    "print(\"M * x1000: \", M.dot(x0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
